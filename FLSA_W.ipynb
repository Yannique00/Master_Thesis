{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from FuzzyTM import FLSA_W\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install FuzzyTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pseudo_id</th>\n",
       "      <th>verslagen_report_tags</th>\n",
       "      <th>verslagen_report_content</th>\n",
       "      <th>verslagen_report_start_date</th>\n",
       "      <th>date</th>\n",
       "      <th>alltext</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>046D1FFEBDD40E1665D0ABA6DD8FC9F8BC4351C6</td>\n",
       "      <td>Klinische Brief</td>\n",
       "      <td>Dhr. A.J. Dingemans, huisarts\\r\\n[STREETNAME] ...</td>\n",
       "      <td>2020-11-26 15:06:00</td>\n",
       "      <td>2020-11-26 15:06:00</td>\n",
       "      <td>dhr aj dingemans huisarts streetnaam city datu...</td>\n",
       "      <td>['dhr', 'aj', 'dingemans', 'huisarts', 'street...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>046D1FFEBDD40E1665D0ABA6DD8FC9F8BC4351C6</td>\n",
       "      <td>Consult, Kliniek: vervolgconsult</td>\n",
       "      <td>Samenvatting: \\nRectaal bloedverlies obv diver...</td>\n",
       "      <td>2020-11-26 09:53:00</td>\n",
       "      <td>2020-11-26 09:53:00</td>\n",
       "      <td>samenvatting rectaal bloedverlie obvn divertik...</td>\n",
       "      <td>['samenvatting', 'rectaal', 'bloedverlie', 'ob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>046D1FFEBDD40E1665D0ABA6DD8FC9F8BC4351C6</td>\n",
       "      <td>Poliklinische Brief</td>\n",
       "      <td>COLOSCOPIE\\r\\n\\r\\nBetreft\\r\\nMw. [INITIALS] [L...</td>\n",
       "      <td>2020-11-25 14:13:00</td>\n",
       "      <td>2020-11-25 14:13:00</td>\n",
       "      <td>coloscopie betreffen mw initials lastname adre...</td>\n",
       "      <td>['coloscopie', 'betreffen', 'mw', 'initials', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>046D1FFEBDD40E1665D0ABA6DD8FC9F8BC4351C6</td>\n",
       "      <td>Poliklinische Brief</td>\n",
       "      <td>GASTROSCOPIE\\r\\n\\r\\nBetreft\\r\\nMw. [INITIALS] ...</td>\n",
       "      <td>2020-11-25 13:48:00</td>\n",
       "      <td>2020-11-25 13:48:00</td>\n",
       "      <td>gastroscopie betreffen mw initials lastname ad...</td>\n",
       "      <td>['gastroscopie', 'betreffen', 'mw', 'initials'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>046D1FFEBDD40E1665D0ABA6DD8FC9F8BC4351C6</td>\n",
       "      <td>Consult, Kliniek: vervolgconsult</td>\n",
       "      <td>Samenvatting: \\nRectaal bloedverlies ; eenmali...</td>\n",
       "      <td>2020-11-25 08:47:00</td>\n",
       "      <td>2020-11-25 08:47:00</td>\n",
       "      <td>samenvatting rectaal bloedverlie eenmalig hd h...</td>\n",
       "      <td>['samenvatting', 'rectaal', 'bloedverlie', 'ee...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  pseudo_id             verslagen_report_tags  \\\n",
       "0  046D1FFEBDD40E1665D0ABA6DD8FC9F8BC4351C6                   Klinische Brief   \n",
       "1  046D1FFEBDD40E1665D0ABA6DD8FC9F8BC4351C6  Consult, Kliniek: vervolgconsult   \n",
       "2  046D1FFEBDD40E1665D0ABA6DD8FC9F8BC4351C6               Poliklinische Brief   \n",
       "3  046D1FFEBDD40E1665D0ABA6DD8FC9F8BC4351C6               Poliklinische Brief   \n",
       "4  046D1FFEBDD40E1665D0ABA6DD8FC9F8BC4351C6  Consult, Kliniek: vervolgconsult   \n",
       "\n",
       "                            verslagen_report_content  \\\n",
       "0  Dhr. A.J. Dingemans, huisarts\\r\\n[STREETNAME] ...   \n",
       "1  Samenvatting: \\nRectaal bloedverlies obv diver...   \n",
       "2  COLOSCOPIE\\r\\n\\r\\nBetreft\\r\\nMw. [INITIALS] [L...   \n",
       "3  GASTROSCOPIE\\r\\n\\r\\nBetreft\\r\\nMw. [INITIALS] ...   \n",
       "4  Samenvatting: \\nRectaal bloedverlies ; eenmali...   \n",
       "\n",
       "  verslagen_report_start_date                 date  \\\n",
       "0         2020-11-26 15:06:00  2020-11-26 15:06:00   \n",
       "1         2020-11-26 09:53:00  2020-11-26 09:53:00   \n",
       "2         2020-11-25 14:13:00  2020-11-25 14:13:00   \n",
       "3         2020-11-25 13:48:00  2020-11-25 13:48:00   \n",
       "4         2020-11-25 08:47:00  2020-11-25 08:47:00   \n",
       "\n",
       "                                             alltext  \\\n",
       "0  dhr aj dingemans huisarts streetnaam city datu...   \n",
       "1  samenvatting rectaal bloedverlie obvn divertik...   \n",
       "2  coloscopie betreffen mw initials lastname adre...   \n",
       "3  gastroscopie betreffen mw initials lastname ad...   \n",
       "4  samenvatting rectaal bloedverlie eenmalig hd h...   \n",
       "\n",
       "                                              tokens  \n",
       "0  ['dhr', 'aj', 'dingemans', 'huisarts', 'street...  \n",
       "1  ['samenvatting', 'rectaal', 'bloedverlie', 'ob...  \n",
       "2  ['coloscopie', 'betreffen', 'mw', 'initials', ...  \n",
       "3  ['gastroscopie', 'betreffen', 'mw', 'initials'...  \n",
       "4  ['samenvatting', 'rectaal', 'bloedverlie', 'ee...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('a:/df_cleaned.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [dhr, aj, dingemans, huisarts, streetnaam, cit...\n",
       "1    [samenvatting, rectaal, bloedverlie, obvn, div...\n",
       "2    [coloscopie, betreffen, mw, initials, lastname...\n",
       "3    [gastroscopie, betreffen, mw, initials, lastna...\n",
       "4    [samenvatting, rectaal, bloedverlie, eenmalig,...\n",
       "Name: tokens, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If data['tokens'] is not a list of tokens, we need to convert it to a list of tokens\n",
    "data['tokens'] = data['tokens'].apply(\n",
    "    lambda x: [word.strip(\" '\\\"\") for word in x.strip(\"[]\").split(', ')] if isinstance(x, str) else x\n",
    ")\n",
    "data['tokens'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(n_topics, n_words):\n",
    "    model = FLSA_W(\n",
    "        input_file=data['tokens'].to_list(),\n",
    "        num_topics=n_topics,\n",
    "        num_words=n_words,\n",
    "    )\n",
    "    pwgt, ptgd = model.get_matrices() # train model\n",
    "    return model\n",
    "\n",
    "def retrain_model(n_topics, n_words, token_list):\n",
    "    model = FLSA_W(\n",
    "        input_file=token_list,\n",
    "        num_topics=n_topics,\n",
    "        num_words=n_words,\n",
    "    )\n",
    "    pwgt, ptgd = model.get_matrices() # train model\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model):\n",
    "    print('The following topics were found:')\n",
    "    for topic in model.show_topics(representation='words'):\n",
    "        print(topic)\n",
    "        \n",
    "    print('Coherence score:', model.get_coherence_score())\n",
    "    print('Diversity score:', model.get_diversity_score())\n",
    "    print('Interpretability score:', model.get_interpretability_score())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_calculate_entropy', '_calculate_idf', '_calculate_normal', '_calculate_probidf', '_check_passed_variables', '_check_variables', '_create_dictlist_percentile', '_create_dictlist_topn', '_create_index_dicts', '_create_p_log_p_ij', '_create_partition_matrix', '_create_prob_document_j', '_create_prob_topic_k', '_create_prob_word_i', '_create_probability_matrices', '_create_projected_data', '_create_sparse_binary_dtm', '_create_sparse_global_term_weights', '_create_sparse_local_term_weights', '_create_sum_words', '_create_vocabulary', '_index_to_word', '_prob_document_j', '_prob_topic_k', '_prob_word_given_document', '_prob_word_given_topic', '_prob_word_i', '_sum_words', '_vocabulary', '_vocabulary_size', '_word_to_index', 'algorithm', 'cluster_method', 'coherence_score', 'diversity_score', 'get_coherence_score', 'get_diversity_score', 'get_index_to_word', 'get_input_file', 'get_interpretability_score', 'get_matrices', 'get_prob_document_j', 'get_prob_topic_k', 'get_prob_word_i', 'get_topic_embedding', 'get_vocabulary', 'get_vocabulary_size', 'get_word_to_index', 'input_file', 'load', 'min_count', 'num_topics', 'num_words', 'save', 'show_topics', 'svd_factors', 'vector_size', 'window', 'word_weighting', 'workers']\n"
     ]
    }
   ],
   "source": [
    "flsa_W = FLSA_W(\n",
    "    input_file=data['tokens'].to_list(),\n",
    "    num_topics=10,\n",
    "    num_words=10,\n",
    ")\n",
    "\n",
    "print(dir(flsa_W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample tokens[0]: ['dhr', 'aj', 'dingemans', 'huisarts', 'streetnaam', 'city', 'datum', 'Kenmerk', 'patientid', 'bsn', 'bsn', 'betreffen', 'mevrouw', 'initials', 'lastname', 'geb', 'birthdate', 'streetnaam', 'zip', 'city', 'tel', 'phonenumber', 'geacht', 'collega', 'bovengenoemde', 'patiënte', 'opnemen', 'afdeling', 'maag', 'darm', 'leverziekt', 'verband', 'melaena', 'rectaal', 'bloedverlie', 'voorgeschiedenis', 'diep', 'veneuaz', 'trombose', 'longembolie', 'cholecystectomie', 'diverticulitis', 'atriumfibrilleren', 'spontaan', 'conversie', 'sinusritme', 'melena', 'waarvoor', 'verklaring', 'vinden', 'verband', 'stabiel', 'hb', 'overleg', 'patiënt', 'expectatief', 'beleid', 'vermoeidheid', 'sinusbradycardie', 'waarvoor', 'stop', 'metoprolol', 'tambocor', 'anamnees', 'vanmiddag', 'fors', 'Helderrood', 'bloedverlie', 'stolsel', 'vermengen', 'ontlasting', 'zwart', 'kleur', 'dag', 'zeuren', 'pijn', 'bovenbuik', 'maagpijn', 'waarvoor', 'stoppen', 'koffie', 'drinken', 'vet', 'eten', 'dag', 'ontlasting', 'intaak', 'bloed', 'zwart', 'verkleuring', 'bemerken', 'tractus', 'anamnees', 'bijdragen', 'mn', 'lwklachten', 'all', 'penicilline', 'urticaria', 'lichamelijk', 'onderzoek', 'controle', 'hr', 'bpm', 'nibp', 'mmhg', 'temp', 'alg', 'acuut', 'ziek', 'duidelijk', 'anemisch', 'hh', 'pearl', 'lymfadenopathie', 'Cor', 'souffle', 'pulm', 'vag', 'beiderzijds', 'bijgeluiod', 'abd', 'normaal', 'peristaltiek', 'wisselen', 'tympanie', 'soepel', 'abdomen', 'mild', 'drukpijn', 'epigastrio', 'loslaatpijn', 'murphy', 'rt', 'Helderrood', 'bloed', 'handschoen', 'feces', 'afwijking', 'palpabel', 'hemorroïden', 'aanvullen', 'onderzoek', 'laboratorium', 'hematologie', 'crp', 'mgl', 'hemoglobine', 'Mmoll', 'hematocriet', 'll', 'erytrocyte', 'mcv', 'fl', 'leukocyt', 'trombocyt', 'hemostase', 'aptt', 'sec', 'pt', 'sec', 'inr', 'bloedgroep', 'bloedgroep', 'neg', 'iat', 'neg', 'negatief', 'chemie', 'glucose', 'mmoll', 'natrium', 'Mmoll', 'kalium', 'Mmoll', 'ureum', 'mmoll', 'kreatinine', 'µmoll', 'Egfr', 'ckdepi', 'bilirubine', 'totaal', 'µmoll', 'alkalisch', 'fosfatase', 'ul', 'ggt', 'ul', 'asat', 'ul', 'alat', 'ul', 'ld', 'ul', 'lipase', 'ul', 'albumine', 'gl', 'gastroscopie', 'bloed', 'bloedingsbron', 'gastroscopie', 'coloscopie', 'coloscopie', 'colon', 'ascendens', 'lang', 'darm', 'scopie', 'klep', 'bloeding', 'stoppen', 'bloedingsbron', 'vinden', 'pandiverticulose', 'Sigmoid', 'waarschijnlijkheidsdiagnose', 'divertikelbloeding', 'laboratorium', 'hematologie', 'hemoglobine', 'Mmoll', 'mcv', 'fl', 'beloop', 'patiënte', 'opnemen', 'verband', 'melaena', 'hierbij', 'Helderrood', 'rectaal', 'bloedverlie', 'acenocoumarol', 'acenocoumarol', 'staken', 'couperen', 'verdenking', 'zowel', 'hoog', 'laag', 'tractus', 'digestivus', 'bloeding', 'starten', 'pantoprazol', 'perfusor', 'patiënt', 'voorbereiden', 'zowel', 'gastro', 'coloscopie', 'avond', 'patiënte', 'nogmaals', 'fors', 'melaena', 'hypotensief', 'rr', 'waarvoor', 'infuus', 'starten', 'patiënte', 'hierbij', 'klacht', 'volgen', 'dag', 'krijgen', 'patiënte', 'zowel', 'gasto', 'coloscopie', 'waarop', 'uitbreiden', 'diverticulose', 'zien', 'actief', 'bloedingsbron', 'waardoor', 'werkdiagnose', 'divertikelbloeding', 'coloscopie', 'coecumbodem', 'volledig', 'beoordeeld', 'patiënte', 'familie', 'bespreken', 'theoretisch', 'coecumproce', 'zitten', 'kans', 'klein', 'caecum', 'redelijk', 'overzien', 'hiervoor', 'ctcolografie', 'maken', 'samenspraak', 'patiënte', 'familie', 'hiervan', 'afzien', 'endoscopie', 'rectaal', 'bloedverlie', 'waarnemen', 'patiënte', 'goed', 'conditie', 'ontslag', 'huis', 'medicatie', 'latanoprosten', 'oogdruppel', 'minim', 'oog', 'per', 'dag', 'druppel', 'oog', 'hyaluronzuur', 'oogdruppel', 'fl', 'oog', 'nodig', 'per', 'dag', 'druppel', 'acenocoumarol', 'tablet', 'mg', 'oraal', 'per', 'dag', 'trombosedienst', 'macrogolzout', 'pdr', 'drank', 'movicolongeneriek', 'oraal', 'per', 'dag', 'stuk', 'furosemide', 'tablet', 'mg', 'oraal', 'per', 'dag', 'stuk', 'tijdelijk', 'stoppen', 'metocloprami', 'tablet', 'mg', 'oraal', 'nodig', 'per', 'dag', 'stuk', 'behandelbeperking', 'kiezen', 'behandelbeperking', 'reanimeren', 'nee', 'ic', 'opname', 'beslissen', 'beademen', 'nee', 'conclusie', 'divertikelbloeding', 'acenocoumarol', 'opnaam', 'meermaals', 'hypotensie', 'rr', 'klacht', 'beleid', 'acenocoumarol', 'dosering', 'hervatten', 'furosemide', 'tijdelijk', 'staken', 'ivm', 'laag', 'tensie', 'patiënt', 'meet', 'bloeddruk', 'thuis', 'overnieuw', 'nemen', 'hierover', 'contact', 'vriendelijk', 'groet', 'bukkem', 'semiarts', 'maagdarmleverziekt', 'vriendelijk', 'groet', 'jt', 'kamphuis', 'maagdarmleverarts', 'agb', 'brief', 'elektronisch', 'accorderen', 'ondertekenen']\n",
      "Length of tokens: 9577\n",
      "Type of tokens[0]: <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "tokens = data['tokens'].to_list()\n",
    "print(\"Sample tokens[0]:\", tokens[0])\n",
    "print(\"Length of tokens:\", len(tokens))\n",
    "print(\"Type of tokens[0]:\", type(tokens[0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of empty docs: 0\n"
     ]
    }
   ],
   "source": [
    "empty_docs = [i for i, doc in enumerate(data['tokens']) if not doc]\n",
    "print(f\"Number of empty docs: {len(empty_docs)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy version: 1.24.4\n",
      "SciPy version: 1.10.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "print(\"NumPy version:\", np.__version__)\n",
    "print(\"SciPy version:\", scipy.__version__)\n",
    "\n",
    "# NumPy version: 1.24.4\n",
    "# SciPy version: 1.10.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_matrices(self):\n",
    "#     # Example: Inside the FLSA_W class\n",
    "#     sparse_document_term_matrix = self._create_sparse_local_term_weights(...)\n",
    "#     sparse_global_term_weighting = self._create_sparse_global_term_weights(...)\n",
    "#     return sparse_document_term_matrix, sparse_global_term_weighting\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pwgt, ptgd = flsa_W.get_matrices()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example tokens: ['dhr', 'aj', 'dingemans', 'huisarts', 'streetnaam', 'city', 'datum', 'Kenmerk', 'patientid', 'bsn', 'bsn', 'betreffen', 'mevrouw', 'initials', 'lastname', 'geb', 'birthdate', 'streetnaam', 'zip', 'city', 'tel', 'phonenumber', 'geacht', 'collega', 'bovengenoemde', 'patiënte', 'opnemen', 'afdeling', 'maag', 'darm', 'leverziekt', 'verband', 'melaena', 'rectaal', 'bloedverlie', 'voorgeschiedenis', 'diep', 'veneuaz', 'trombose', 'longembolie', 'cholecystectomie', 'diverticulitis', 'atriumfibrilleren', 'spontaan', 'conversie', 'sinusritme', 'melena', 'waarvoor', 'verklaring', 'vinden', 'verband', 'stabiel', 'hb', 'overleg', 'patiënt', 'expectatief', 'beleid', 'vermoeidheid', 'sinusbradycardie', 'waarvoor', 'stop', 'metoprolol', 'tambocor', 'anamnees', 'vanmiddag', 'fors', 'Helderrood', 'bloedverlie', 'stolsel', 'vermengen', 'ontlasting', 'zwart', 'kleur', 'dag', 'zeuren', 'pijn', 'bovenbuik', 'maagpijn', 'waarvoor', 'stoppen', 'koffie', 'drinken', 'vet', 'eten', 'dag', 'ontlasting', 'intaak', 'bloed', 'zwart', 'verkleuring', 'bemerken', 'tractus', 'anamnees', 'bijdragen', 'mn', 'lwklachten', 'all', 'penicilline', 'urticaria', 'lichamelijk', 'onderzoek', 'controle', 'hr', 'bpm', 'nibp', 'mmhg', 'temp', 'alg', 'acuut', 'ziek', 'duidelijk', 'anemisch', 'hh', 'pearl', 'lymfadenopathie', 'Cor', 'souffle', 'pulm', 'vag', 'beiderzijds', 'bijgeluiod', 'abd', 'normaal', 'peristaltiek', 'wisselen', 'tympanie', 'soepel', 'abdomen', 'mild', 'drukpijn', 'epigastrio', 'loslaatpijn', 'murphy', 'rt', 'Helderrood', 'bloed', 'handschoen', 'feces', 'afwijking', 'palpabel', 'hemorroïden', 'aanvullen', 'onderzoek', 'laboratorium', 'hematologie', 'crp', 'mgl', 'hemoglobine', 'Mmoll', 'hematocriet', 'll', 'erytrocyte', 'mcv', 'fl', 'leukocyt', 'trombocyt', 'hemostase', 'aptt', 'sec', 'pt', 'sec', 'inr', 'bloedgroep', 'bloedgroep', 'neg', 'iat', 'neg', 'negatief', 'chemie', 'glucose', 'mmoll', 'natrium', 'Mmoll', 'kalium', 'Mmoll', 'ureum', 'mmoll', 'kreatinine', 'µmoll', 'Egfr', 'ckdepi', 'bilirubine', 'totaal', 'µmoll', 'alkalisch', 'fosfatase', 'ul', 'ggt', 'ul', 'asat', 'ul', 'alat', 'ul', 'ld', 'ul', 'lipase', 'ul', 'albumine', 'gl', 'gastroscopie', 'bloed', 'bloedingsbron', 'gastroscopie', 'coloscopie', 'coloscopie', 'colon', 'ascendens', 'lang', 'darm', 'scopie', 'klep', 'bloeding', 'stoppen', 'bloedingsbron', 'vinden', 'pandiverticulose', 'Sigmoid', 'waarschijnlijkheidsdiagnose', 'divertikelbloeding', 'laboratorium', 'hematologie', 'hemoglobine', 'Mmoll', 'mcv', 'fl', 'beloop', 'patiënte', 'opnemen', 'verband', 'melaena', 'hierbij', 'Helderrood', 'rectaal', 'bloedverlie', 'acenocoumarol', 'acenocoumarol', 'staken', 'couperen', 'verdenking', 'zowel', 'hoog', 'laag', 'tractus', 'digestivus', 'bloeding', 'starten', 'pantoprazol', 'perfusor', 'patiënt', 'voorbereiden', 'zowel', 'gastro', 'coloscopie', 'avond', 'patiënte', 'nogmaals', 'fors', 'melaena', 'hypotensief', 'rr', 'waarvoor', 'infuus', 'starten', 'patiënte', 'hierbij', 'klacht', 'volgen', 'dag', 'krijgen', 'patiënte', 'zowel', 'gasto', 'coloscopie', 'waarop', 'uitbreiden', 'diverticulose', 'zien', 'actief', 'bloedingsbron', 'waardoor', 'werkdiagnose', 'divertikelbloeding', 'coloscopie', 'coecumbodem', 'volledig', 'beoordeeld', 'patiënte', 'familie', 'bespreken', 'theoretisch', 'coecumproce', 'zitten', 'kans', 'klein', 'caecum', 'redelijk', 'overzien', 'hiervoor', 'ctcolografie', 'maken', 'samenspraak', 'patiënte', 'familie', 'hiervan', 'afzien', 'endoscopie', 'rectaal', 'bloedverlie', 'waarnemen', 'patiënte', 'goed', 'conditie', 'ontslag', 'huis', 'medicatie', 'latanoprosten', 'oogdruppel', 'minim', 'oog', 'per', 'dag', 'druppel', 'oog', 'hyaluronzuur', 'oogdruppel', 'fl', 'oog', 'nodig', 'per', 'dag', 'druppel', 'acenocoumarol', 'tablet', 'mg', 'oraal', 'per', 'dag', 'trombosedienst', 'macrogolzout', 'pdr', 'drank', 'movicolongeneriek', 'oraal', 'per', 'dag', 'stuk', 'furosemide', 'tablet', 'mg', 'oraal', 'per', 'dag', 'stuk', 'tijdelijk', 'stoppen', 'metocloprami', 'tablet', 'mg', 'oraal', 'nodig', 'per', 'dag', 'stuk', 'behandelbeperking', 'kiezen', 'behandelbeperking', 'reanimeren', 'nee', 'ic', 'opname', 'beslissen', 'beademen', 'nee', 'conclusie', 'divertikelbloeding', 'acenocoumarol', 'opnaam', 'meermaals', 'hypotensie', 'rr', 'klacht', 'beleid', 'acenocoumarol', 'dosering', 'hervatten', 'furosemide', 'tijdelijk', 'staken', 'ivm', 'laag', 'tensie', 'patiënt', 'meet', 'bloeddruk', 'thuis', 'overnieuw', 'nemen', 'hierover', 'contact', 'vriendelijk', 'groet', 'bukkem', 'semiarts', 'maagdarmleverziekt', 'vriendelijk', 'groet', 'jt', 'kamphuis', 'maagdarmleverarts', 'agb', 'brief', 'elektronisch', 'accorderen', 'ondertekenen']\n",
      "Length of token list: 9577\n"
     ]
    }
   ],
   "source": [
    "print(\"Example tokens:\", data['tokens'].iloc[0])\n",
    "print(\"Length of token list:\", len(data['tokens']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling _create_probability_matrices with:\n",
      "  - _prob_word_given_document: True\n",
      "  - _prob_document_j: None\n",
      "  - _prob_word_i: None\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'matrix' object has no attribute 'multiply'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 38\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# # pwgt, ptgd = flsa_W.get_matrices() # this trains the model\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# import numpy as np\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     36\u001b[0m \n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Then call get_matrices\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m pwgt, ptgd \u001b[38;5;241m=\u001b[39m \u001b[43mflsa_W\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_matrices\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Y.vanMegen\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\FuzzyTM\\FuzzyTM.py:1425\u001b[0m, in \u001b[0;36mFLSA_W.get_matrices\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1423\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  - _prob_document_j:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prob_document_j)\n\u001b[0;32m   1424\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  - _prob_word_i:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prob_word_i)\n\u001b[1;32m-> 1425\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_probability_matrices\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1426\u001b[0m \u001b[43m    \u001b[49m\u001b[43malgorithm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mflsa-w\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1427\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprob_topic_given_word_transpose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpartition_matrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1428\u001b[0m \u001b[43m    \u001b[49m\u001b[43mglobal_term_weights\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msparse_global_term_weighting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1429\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Y.vanMegen\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\FuzzyTM\\FuzzyTM.py:775\u001b[0m, in \u001b[0;36mFuzzyTM._create_probability_matrices\u001b[1;34m(self, algorithm, prob_topic_given_document_transpose, prob_topic_given_word_transpose, local_term_weights, global_term_weights)\u001b[0m\n\u001b[0;32m    770\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m algorithm \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[0;32m    771\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mflsa-v\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    772\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mflsa-e\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    773\u001b[0m         ]:\n\u001b[0;32m    774\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prob_word_given_document \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(local_term_weights \u001b[38;5;241m/\u001b[39m local_term_weights\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m--> 775\u001b[0m prob_document_given_word \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prob_word_given_document\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultiply\u001b[49m(np\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prob_document_j, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)))\u001b[38;5;241m.\u001b[39mtoarray() \u001b[38;5;241m/\u001b[39mnp\u001b[38;5;241m.\u001b[39mreshape(np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prob_word_i), (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    776\u001b[0m prob_document_given_topic \u001b[38;5;241m=\u001b[39m prob_document_given_word\u001b[38;5;241m.\u001b[39mdot(\n\u001b[0;32m    777\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prob_word_given_topic\n\u001b[0;32m    778\u001b[0m     )\n\u001b[0;32m    779\u001b[0m prob_topic_given_document \u001b[38;5;241m=\u001b[39m ((prob_document_given_topic \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prob_topic_k)\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m/\u001b[39m\n\u001b[0;32m    780\u001b[0m                                    \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prob_document_j)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'matrix' object has no attribute 'multiply'"
     ]
    }
   ],
   "source": [
    "# # pwgt, ptgd = flsa_W.get_matrices() # this trains the model\n",
    "\n",
    "# import numpy as np\n",
    "# from types import MethodType\n",
    "\n",
    "# def patched_create_probability_matrices(self, algorithm, \n",
    "#                                         prob_topic_given_document_transpose=None, \n",
    "#                                         prob_topic_given_word_transpose=None, \n",
    "#                                         local_term_weights=None, \n",
    "#                                         global_term_weights=None):\n",
    "    \n",
    "#     if algorithm in ['flsa-v', 'flsa-e']:\n",
    "#         self._prob_word_given_document = np.asarray(local_term_weights / local_term_weights.sum(1)).T\n",
    "\n",
    "#     elif algorithm == 'flsa-w':\n",
    "#         self._prob_word_given_document = np.asarray(global_term_weights / global_term_weights.sum(1)).T\n",
    "\n",
    "#     for attr in ['_prob_word_given_document', '_prob_document_j', '_prob_word_i',\n",
    "#                 '_prob_word_given_topic', '_prob_topic_k']:\n",
    "#         if getattr(self, attr) is None:\n",
    "#             raise ValueError(f\"{attr} is None — can't compute matrices.\")\n",
    "\n",
    "#     A = np.asarray(self._prob_word_given_document.T)\n",
    "#     B = np.reshape(self._prob_document_j, (-1, 1))\n",
    "#     numerator = A * B\n",
    "#     prob_document_given_word = numerator / np.reshape(np.array(self._prob_word_i), (1, -1))\n",
    "    \n",
    "#     prob_document_given_topic = prob_document_given_word.dot(self._prob_word_given_topic)\n",
    "#     prob_topic_given_document = ((prob_document_given_topic * self._prob_topic_k).T /\n",
    "#                                  self._prob_document_j)\n",
    "    \n",
    "#     return self._prob_word_given_topic, prob_topic_given_document\n",
    "\n",
    "# # Patch the method\n",
    "# flsa_W._create_probability_matrices = MethodType(patched_create_probability_matrices, flsa_W)\n",
    "\n",
    "# Then call get_matrices\n",
    "pwgt, ptgd = flsa_W.get_matrices()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "FuzzyTM._create_sparse_local_term_weights() missing 3 required positional arguments: 'input_file', 'vocabulary_size', and 'word_to_index'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Manually trigger internal steps that initialize key probability variables\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m local_weights \u001b[38;5;241m=\u001b[39m \u001b[43mflsa_W\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_sparse_local_term_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m global_weights \u001b[38;5;241m=\u001b[39m flsa_W\u001b[38;5;241m.\u001b[39m_create_sparse_global_term_weights(local_weights)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# These are the missing steps\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: FuzzyTM._create_sparse_local_term_weights() missing 3 required positional arguments: 'input_file', 'vocabulary_size', and 'word_to_index'"
     ]
    }
   ],
   "source": [
    "# Manually trigger internal steps that initialize key probability variables\n",
    "local_weights = flsa_W._create_sparse_local_term_weights()\n",
    "global_weights = flsa_W._create_sparse_global_term_weights(local_weights)\n",
    "\n",
    "# These are the missing steps\n",
    "flsa_W._prob_document_j = flsa_W._create_prob_document_j(global_weights)\n",
    "flsa_W._prob_word_i = flsa_W._create_prob_word_i(global_weights)\n",
    "\n",
    "# Continue with standard flow\n",
    "projected = flsa_W._create_projected_data(\n",
    "    algorithm='flsa-w',\n",
    "    sparse_weighted_matrix=global_weights,\n",
    "    svd_factors=flsa_W.svd_factors\n",
    ")\n",
    "\n",
    "partition = flsa_W._create_partition_matrix(\n",
    "    data=projected,\n",
    "    number_of_clusters=flsa_W.num_topics,\n",
    "    method=flsa_W.cluster_method\n",
    ")\n",
    "\n",
    "# Now get the probability matrices\n",
    "pwgt, ptgd = flsa_W._create_probability_matrices(\n",
    "    algorithm='flsa-w',\n",
    "    prob_topic_given_word_transpose=partition,\n",
    "    global_term_weights=global_weights\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "FuzzyTM._create_sparse_local_term_weights() missing 3 required positional arguments: 'input_file', 'vocabulary_size', and 'word_to_index'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m flsa_W \u001b[38;5;241m=\u001b[39m FLSA_W(input_file\u001b[38;5;241m=\u001b[39mdata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtokens\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto_list(), num_topics\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, num_words\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Run internal setup manually\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m local_weights \u001b[38;5;241m=\u001b[39m \u001b[43mflsa_W\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_sparse_local_term_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m global_weights \u001b[38;5;241m=\u001b[39m flsa_W\u001b[38;5;241m.\u001b[39m_create_sparse_global_term_weights(local_weights)\n\u001b[0;32m      7\u001b[0m projected \u001b[38;5;241m=\u001b[39m flsa_W\u001b[38;5;241m.\u001b[39m_create_projected_data(algorithm\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mflsa-w\u001b[39m\u001b[38;5;124m'\u001b[39m, sparse_weighted_matrix\u001b[38;5;241m=\u001b[39mglobal_weights, svd_factors\u001b[38;5;241m=\u001b[39mflsa_W\u001b[38;5;241m.\u001b[39msvd_factors)\n",
      "\u001b[1;31mTypeError\u001b[0m: FuzzyTM._create_sparse_local_term_weights() missing 3 required positional arguments: 'input_file', 'vocabulary_size', and 'word_to_index'"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "flsa_W = FLSA_W(input_file=data['tokens'].to_list(), num_topics=10, num_words=10)\n",
    "\n",
    "# Run internal setup manually\n",
    "local_weights = flsa_W._create_sparse_local_term_weights()\n",
    "global_weights = flsa_W._create_sparse_global_term_weights(local_weights)\n",
    "projected = flsa_W._create_projected_data(algorithm='flsa-w', sparse_weighted_matrix=global_weights, svd_factors=flsa_W.svd_factors)\n",
    "partition = flsa_W._create_partition_matrix(data=projected, number_of_clusters=flsa_W.num_topics, method=flsa_W.cluster_method)\n",
    "\n",
    "# Force matrix generation\n",
    "pwgt, ptgd = flsa_W._create_probability_matrices(\n",
    "    algorithm='flsa-w',\n",
    "    prob_topic_given_word_transpose=partition,\n",
    "    global_term_weights=global_weights\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.0102*\"hb\" + 0.0089*\"dr\" + 0.0077*\"iom\" + 0.0076*\"hemoglobine\" + 0.0074*\"phonenumber\" + 0.0074*\"conclusie\" + 0.0073*\"huisarts\" + 0.0073*\"totaal\" + 0.0073*\"ontlasting\" + 0.0072*\"reden\"'), (1, '0.0086*\"dalen\" + 0.008*\"sept\" + 0.0078*\"hyperlipidemie\" + 0.0076*\"stabiel\" + 0.0075*\"meten\" + 0.0071*\"okt\" + 0.0068*\"veneus\" + 0.0067*\"oktober\" + 0.0065*\"reguleeren\" + 0.0065*\"verlagen\"'), (2, '0.0011*\"handeling\" + 0.0011*\"introductie\" + 0.0011*\"consent\" + 0.0011*\"informed\" + 0.0011*\"rvc\" + 0.0011*\"geboortedatum\" + 0.0011*\"speciële\" + 0.0011*\"adresgegevens\" + 0.0011*\"event\" + 0.001*\"insulin\"'), (3, '0.0011*\"medewerk\" + 0.0009*\"scorelijzen\" + 0.0007*\"basisdosering\" + 0.0004*\"regievoeringempowerment\" + 0.0004*\"realiser\" + 0.0003*\"memo\" + 0.0003*\"simm\" + 0.0003*\"sehperiode\" + 0.0003*\"mdlverpleegkundig\" + 0.0003*\"wonddebridement\"'), (4, '0.003*\"vpk\" + 0.0024*\"verpleegkundig\" + 0.0023*\"uitslag\" + 0.0023*\"colon\" + 0.0023*\"ferinject\" + 0.0022*\"pc\" + 0.0022*\"Melena\" + 0.0022*\"dm\" + 0.0021*\"sputovamo\" + 0.0021*\"Clopidogrel\"'), (5, '0.0018*\"verwijzer\" + 0.0017*\"uitvoeren\" + 0.0017*\"hd\" + 0.0017*\"voorbereiding\" + 0.0017*\"bespreking\" + 0.0016*\"endoscopie\" + 0.0016*\"verslag\" + 0.0016*\"akkoord\" + 0.0015*\"borg\" + 0.0015*\"overdracht\"'), (6, '0.0099*\"secundair\" + 0.0092*\"onvoldoende\" + 0.0087*\"poli\" + 0.0085*\"status\" + 0.0085*\"cy\" + 0.008*\"insufficiëntie\" + 0.0079*\"urosepsis\" + 0.0077*\"hyperparathyreoïdie\" + 0.0075*\"geneeskun\" + 0.0073*\"niertransplantatie\"'), (7, '0.001*\"aanvraag\" + 0.0007*\"vce\" + 0.0007*\"premedicatie\" + 0.0006*\"klasse\" + 0.0006*\"noac\" + 0.0006*\"Aanvraag\" + 0.0006*\"ileocoloscopie\" + 0.0006*\"zkh\" + 0.0006*\"triage\" + 0.0006*\"trombosediensten\"'), (8, '0.004*\"vandaag\" + 0.0037*\"contact\" + 0.0037*\"leeftijd\" + 0.0036*\"start\" + 0.0036*\"tia\" + 0.0035*\"ferriprief\" + 0.0035*\"gebruiken\" + 0.0035*\"klein\" + 0.0034*\"beloop\" + 0.0034*\"klinisch\"'), (9, '0.0009*\"uitinen\" + 0.0007*\"lunch\" + 0.0006*\"doel\" + 0.0006*\"memo\" + 0.0006*\"naamgeving\" + 0.0006*\"podo\" + 0.0005*\"mrsa\" + 0.0005*\"varken\" + 0.0005*\"cumarinederivaat\" + 0.0005*\"Decursus\"')]\n"
     ]
    }
   ],
   "source": [
    "print(flsa_W.show_topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hb', 'dr', 'iom', 'hemoglobine', 'phonenumber', 'conclusie', 'huisarts', 'totaal', 'ontlasting', 'reden']\n",
      "['dalen', 'sept', 'hyperlipidemie', 'stabiel', 'meten', 'okt', 'veneus', 'oktober', 'reguleeren', 'verlagen']\n",
      "['handeling', 'introductie', 'consent', 'informed', 'rvc', 'geboortedatum', 'speciële', 'adresgegevens', 'event', 'insulin']\n",
      "['medewerk', 'scorelijzen', 'basisdosering', 'regievoeringempowerment', 'realiser', 'memo', 'simm', 'sehperiode', 'mdlverpleegkundig', 'wonddebridement']\n",
      "['vpk', 'verpleegkundig', 'uitslag', 'colon', 'ferinject', 'pc', 'Melena', 'dm', 'sputovamo', 'Clopidogrel']\n",
      "['verwijzer', 'uitvoeren', 'hd', 'voorbereiding', 'bespreking', 'endoscopie', 'verslag', 'akkoord', 'borg', 'overdracht']\n",
      "['secundair', 'onvoldoende', 'poli', 'status', 'cy', 'insufficiëntie', 'urosepsis', 'hyperparathyreoïdie', 'geneeskun', 'niertransplantatie']\n",
      "['aanvraag', 'vce', 'premedicatie', 'klasse', 'noac', 'Aanvraag', 'ileocoloscopie', 'zkh', 'triage', 'trombosediensten']\n",
      "['vandaag', 'contact', 'leeftijd', 'start', 'tia', 'ferriprief', 'gebruiken', 'klein', 'beloop', 'klinisch']\n",
      "['uitinen', 'lunch', 'doel', 'memo', 'naamgeving', 'podo', 'mrsa', 'varken', 'cumarinederivaat', 'Decursus']\n"
     ]
    }
   ],
   "source": [
    "for topic in flsa_W.show_topics(representation='words'):\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence score: 0.43297531017886526\n",
      "Diversity score: 0.99\n",
      "Interpretability score: 0.4286455570770766\n"
     ]
    }
   ],
   "source": [
    "print('Coherence score:', flsa_W.get_coherence_score())\n",
    "print('Diversity score:', flsa_W.get_diversity_score())\n",
    "print('Interpretability score:', flsa_W.get_interpretability_score())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'matrix' object has no attribute 'multiply'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# using 5 as the number of topics\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m evaluate_model(model)\n",
      "Cell \u001b[1;32mIn[5], line 7\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(n_topics, n_words)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtrain_model\u001b[39m(n_topics, n_words):\n\u001b[0;32m      2\u001b[0m     model \u001b[38;5;241m=\u001b[39m FLSA_W(\n\u001b[0;32m      3\u001b[0m         input_file\u001b[38;5;241m=\u001b[39mdata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtokens\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto_list(),\n\u001b[0;32m      4\u001b[0m         num_topics\u001b[38;5;241m=\u001b[39mn_topics,\n\u001b[0;32m      5\u001b[0m         num_words\u001b[38;5;241m=\u001b[39mn_words,\n\u001b[0;32m      6\u001b[0m     )\n\u001b[1;32m----> 7\u001b[0m     pwgt, ptgd \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_matrices\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# train model\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[1;32mc:\\Users\\Y.vanMegen\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\FuzzyTM\\FuzzyTM.py:1421\u001b[0m, in \u001b[0;36mFLSA_W.get_matrices\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1411\u001b[0m projected_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_projected_data(\n\u001b[0;32m   1412\u001b[0m     algorithm \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mflsa-w\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1413\u001b[0m     sparse_weighted_matrix \u001b[38;5;241m=\u001b[39m sparse_global_term_weighting,\n\u001b[0;32m   1414\u001b[0m     svd_factors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msvd_factors,\n\u001b[0;32m   1415\u001b[0m     )\n\u001b[0;32m   1416\u001b[0m partition_matrix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_partition_matrix(\n\u001b[0;32m   1417\u001b[0m     data \u001b[38;5;241m=\u001b[39m projected_data,\n\u001b[0;32m   1418\u001b[0m     number_of_clusters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_topics,\n\u001b[0;32m   1419\u001b[0m     method \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcluster_method,\n\u001b[0;32m   1420\u001b[0m     )\n\u001b[1;32m-> 1421\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_probability_matrices\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1422\u001b[0m \u001b[43m    \u001b[49m\u001b[43malgorithm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mflsa-w\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1423\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprob_topic_given_word_transpose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpartition_matrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1424\u001b[0m \u001b[43m    \u001b[49m\u001b[43mglobal_term_weights\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msparse_global_term_weighting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1425\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Y.vanMegen\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\FuzzyTM\\FuzzyTM.py:775\u001b[0m, in \u001b[0;36mFuzzyTM._create_probability_matrices\u001b[1;34m(self, algorithm, prob_topic_given_document_transpose, prob_topic_given_word_transpose, local_term_weights, global_term_weights)\u001b[0m\n\u001b[0;32m    770\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m algorithm \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[0;32m    771\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mflsa-v\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    772\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mflsa-e\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    773\u001b[0m         ]:\n\u001b[0;32m    774\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prob_word_given_document \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(local_term_weights \u001b[38;5;241m/\u001b[39m local_term_weights\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m--> 775\u001b[0m prob_document_given_word \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prob_word_given_document\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultiply\u001b[49m(np\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prob_document_j, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)))\u001b[38;5;241m.\u001b[39mtoarray() \u001b[38;5;241m/\u001b[39mnp\u001b[38;5;241m.\u001b[39mreshape(np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prob_word_i), (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    776\u001b[0m prob_document_given_topic \u001b[38;5;241m=\u001b[39m prob_document_given_word\u001b[38;5;241m.\u001b[39mdot(\n\u001b[0;32m    777\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prob_word_given_topic\n\u001b[0;32m    778\u001b[0m     )\n\u001b[0;32m    779\u001b[0m prob_topic_given_document \u001b[38;5;241m=\u001b[39m ((prob_document_given_topic \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prob_topic_k)\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m/\u001b[39m\n\u001b[0;32m    780\u001b[0m                                    \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prob_document_j)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'matrix' object has no attribute 'multiply'"
     ]
    }
   ],
   "source": [
    "# using 5 as the number of topics\n",
    "model = train_model(5, 10)\n",
    "evaluate_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using 15 as the number of topics\n",
    "model = train_model(15, 10)\n",
    "evaluate_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using 20 as the number of topics\n",
    "model = train_model(20, 10)\n",
    "evaluate_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using 15 as the number of topics and 15 as the number of words\n",
    "model = train_model(15, 15)\n",
    "evaluate_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# elbow plot over 1 to 20 topics -- took +/- 20 minutes to run\n",
    "coherence_scores = []\n",
    "topics = list(range(1, 21))\n",
    "\n",
    "for n_topics in topics:\n",
    "    model = train_model(n_topics, 10)\n",
    "    coherence_scores.append(model.get_coherence_score())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save plot\n",
    "plt.plot(topics, coherence_scores)\n",
    "plt.xlabel('Number of topics')\n",
    "plt.ylabel('Coherence score')\n",
    "plt.title('Elbow plot')\n",
    "plt.savefig('elbow_plot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using 5 as the number of topics and 5 as the number of words\n",
    "model = train_model(5, 5)\n",
    "evaluate_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using 5 as the number of topics and 10 as the number of words\n",
    "model = train_model(5, 10)\n",
    "evaluate_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using 5 as the number of topics and 15 as the number of words\n",
    "model = train_model(5, 15)\n",
    "evaluate_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using 5 as the number of topics and 2 as the number of words\n",
    "model = train_model(5, 2)\n",
    "evaluate_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using 5 as the number of topics and 1 as the number of words\n",
    "model = train_model(5, 1)\n",
    "evaluate_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_words = ['mg', 'x', 'per', 'dag', 'samenvatting', 'beleid', 'conclusie', 'mmolL', 'waarvoor', 'goed', 'wel', 'beloop', \n",
    "                'voorgeschiedenis', 'opdrachten', 'gehad', 'aanvullend', 'bekende', 'voltooid', 'mogelijk', 'gezien', 'city', 'bsn', \n",
    "                'nodig', 'firstname', 'streetname', 'lastname', 'postcode', 'anamnese',\n",
    "                'dd', 'stuk', 'ivm', 'rechts', 'links', 'dr', 'sinds', 'huisarts', 'datum', 'dagen', 'min', 'extra', 'weken', 'algemeen', \n",
    "                'patiënte', 'overige','linker', 'week', 'accepteren', 'maanden', 'waarschijnlijk', 'reden', 'uur', 'verdenking', 'ontslag', \n",
    "                'stop', 'tijd', 'patiënt', 'onderzoek']\n",
    "token_list = data['tokens'].apply(lambda x: [word for word in x if word not in remove_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = retrain_model(5, 5, token_list.to_list())\n",
    "evaluate_model(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
