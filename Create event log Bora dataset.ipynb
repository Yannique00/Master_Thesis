{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pseudo_id</th>\n",
       "      <th>verslagen_report_tags</th>\n",
       "      <th>verslagen_report_content</th>\n",
       "      <th>verslagen_report_start_date</th>\n",
       "      <th>verslagen_report_content_cleaned</th>\n",
       "      <th>content_words</th>\n",
       "      <th>content_words_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>046D1FFEBDD40E1665D0ABA6DD8FC9F8BC4351C6</td>\n",
       "      <td>Klinische Brief</td>\n",
       "      <td>Dhr. A.J. Dingemans, huisarts\\r\\n[STREETNAME] ...</td>\n",
       "      <td>2020-11-26 15:06:00</td>\n",
       "      <td>dhr aj dingemans huisarts streetname nr city d...</td>\n",
       "      <td>['dhr', 'aj', 'dingemans', 'huisarts', 'street...</td>\n",
       "      <td>['dhr', 'aj', 'dingemans', 'huisarts', 'street...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>046D1FFEBDD40E1665D0ABA6DD8FC9F8BC4351C6</td>\n",
       "      <td>Consult, Kliniek: vervolgconsult</td>\n",
       "      <td>Samenvatting: \\nRectaal bloedverlies obv diver...</td>\n",
       "      <td>2020-11-26 09:53:00</td>\n",
       "      <td>samenvatting rectaal bloedverlies obv divertik...</td>\n",
       "      <td>['samenvatting', 'rectaal', 'bloedverlies', 'o...</td>\n",
       "      <td>['samenvatting', 'rectaal', 'bloedverlie', 'ob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>046D1FFEBDD40E1665D0ABA6DD8FC9F8BC4351C6</td>\n",
       "      <td>Poliklinische Brief</td>\n",
       "      <td>COLOSCOPIE\\r\\n\\r\\nBetreft\\r\\nMw. [INITIALS] [L...</td>\n",
       "      <td>2020-11-25 14:13:00</td>\n",
       "      <td>coloscopie betreft mw initials lastname adresg...</td>\n",
       "      <td>['coloscopie', 'betreft', 'mw', 'initials', 'l...</td>\n",
       "      <td>['coloscopie', 'betreffen', 'mw', 'initials', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>046D1FFEBDD40E1665D0ABA6DD8FC9F8BC4351C6</td>\n",
       "      <td>Poliklinische Brief</td>\n",
       "      <td>GASTROSCOPIE\\r\\n\\r\\nBetreft\\r\\nMw. [INITIALS] ...</td>\n",
       "      <td>2020-11-25 13:48:00</td>\n",
       "      <td>gastroscopie betreft mw initials lastname adre...</td>\n",
       "      <td>['gastroscopie', 'betreft', 'mw', 'initials', ...</td>\n",
       "      <td>['gastroscopie', 'betreffen', 'mw', 'initials'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>046D1FFEBDD40E1665D0ABA6DD8FC9F8BC4351C6</td>\n",
       "      <td>Consult, Kliniek: vervolgconsult</td>\n",
       "      <td>Samenvatting: \\nRectaal bloedverlies ; eenmali...</td>\n",
       "      <td>2020-11-25 08:47:00</td>\n",
       "      <td>samenvatting rectaal bloedverlies eenmalig hd ...</td>\n",
       "      <td>['samenvatting', 'rectaal', 'bloedverlies', 'e...</td>\n",
       "      <td>['samenvatting', 'rectaal', 'bloedverlie', 'ee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9572</th>\n",
       "      <td>FD8C682C1F4FDA1E5EC0B760D30875556419BD71</td>\n",
       "      <td>Consult</td>\n",
       "      <td>Samenvatting: \\n1e consult\\r\\n-Type 1e consult...</td>\n",
       "      <td>2015-03-20 08:13:00</td>\n",
       "      <td>samenvatting e consult type e consult uitgebre...</td>\n",
       "      <td>['samenvatting', 'e', 'consult', 'type', 'e', ...</td>\n",
       "      <td>['samenvatting', 'e', 'consult', 'type', 'e', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9573</th>\n",
       "      <td>FD8C682C1F4FDA1E5EC0B760D30875556419BD71</td>\n",
       "      <td>Consult, Kliniek: vervolgconsult</td>\n",
       "      <td>Samenvatting: \\nDecursus\\r\\n-Type decursus: De...</td>\n",
       "      <td>2015-01-14 15:39:00</td>\n",
       "      <td>samenvatting decursus type decursus decursus s...</td>\n",
       "      <td>['samenvatting', 'decursus', 'type', 'decursus...</td>\n",
       "      <td>['samenvatting', 'decursus', 'type', 'decursus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9574</th>\n",
       "      <td>FD8C682C1F4FDA1E5EC0B760D30875556419BD71</td>\n",
       "      <td>Consult, SEH</td>\n",
       "      <td>Samenvatting: \\nVerpleegkundige verslaglegging...</td>\n",
       "      <td>2014-12-21 09:31:00</td>\n",
       "      <td>samenvatting verpleegkundige verslaglegging ve...</td>\n",
       "      <td>['samenvatting', 'verpleegkundige', 'verslagle...</td>\n",
       "      <td>['samenvatting', 'verpleegkundig', 'verslagleg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9575</th>\n",
       "      <td>FD8C682C1F4FDA1E5EC0B760D30875556419BD71</td>\n",
       "      <td>Consult, SEH</td>\n",
       "      <td>Samenvatting: \\nMedisch Dossier\\r\\n[ Vk Sputov...</td>\n",
       "      <td>2010-11-10 21:03:00</td>\n",
       "      <td>samenvatting medisch dossier vk sputovamo leef...</td>\n",
       "      <td>['samenvatting', 'medisch', 'dossier', 'vk', '...</td>\n",
       "      <td>['samenvatting', 'Medisch', 'dossier', 'vk', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9576</th>\n",
       "      <td>FD8C682C1F4FDA1E5EC0B760D30875556419BD71</td>\n",
       "      <td>Consult, SEH</td>\n",
       "      <td>Samenvatting: \\nVerpleegkundige verslaglegging...</td>\n",
       "      <td>2010-11-10 20:29:00</td>\n",
       "      <td>samenvatting verpleegkundige verslaglegging ve...</td>\n",
       "      <td>['samenvatting', 'verpleegkundige', 'verslagle...</td>\n",
       "      <td>['samenvatting', 'verpleegkundig', 'verslagleg...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9577 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     pseudo_id  \\\n",
       "0     046D1FFEBDD40E1665D0ABA6DD8FC9F8BC4351C6   \n",
       "1     046D1FFEBDD40E1665D0ABA6DD8FC9F8BC4351C6   \n",
       "2     046D1FFEBDD40E1665D0ABA6DD8FC9F8BC4351C6   \n",
       "3     046D1FFEBDD40E1665D0ABA6DD8FC9F8BC4351C6   \n",
       "4     046D1FFEBDD40E1665D0ABA6DD8FC9F8BC4351C6   \n",
       "...                                        ...   \n",
       "9572  FD8C682C1F4FDA1E5EC0B760D30875556419BD71   \n",
       "9573  FD8C682C1F4FDA1E5EC0B760D30875556419BD71   \n",
       "9574  FD8C682C1F4FDA1E5EC0B760D30875556419BD71   \n",
       "9575  FD8C682C1F4FDA1E5EC0B760D30875556419BD71   \n",
       "9576  FD8C682C1F4FDA1E5EC0B760D30875556419BD71   \n",
       "\n",
       "                 verslagen_report_tags  \\\n",
       "0                      Klinische Brief   \n",
       "1     Consult, Kliniek: vervolgconsult   \n",
       "2                  Poliklinische Brief   \n",
       "3                  Poliklinische Brief   \n",
       "4     Consult, Kliniek: vervolgconsult   \n",
       "...                                ...   \n",
       "9572                           Consult   \n",
       "9573  Consult, Kliniek: vervolgconsult   \n",
       "9574                      Consult, SEH   \n",
       "9575                      Consult, SEH   \n",
       "9576                      Consult, SEH   \n",
       "\n",
       "                               verslagen_report_content  \\\n",
       "0     Dhr. A.J. Dingemans, huisarts\\r\\n[STREETNAME] ...   \n",
       "1     Samenvatting: \\nRectaal bloedverlies obv diver...   \n",
       "2     COLOSCOPIE\\r\\n\\r\\nBetreft\\r\\nMw. [INITIALS] [L...   \n",
       "3     GASTROSCOPIE\\r\\n\\r\\nBetreft\\r\\nMw. [INITIALS] ...   \n",
       "4     Samenvatting: \\nRectaal bloedverlies ; eenmali...   \n",
       "...                                                 ...   \n",
       "9572  Samenvatting: \\n1e consult\\r\\n-Type 1e consult...   \n",
       "9573  Samenvatting: \\nDecursus\\r\\n-Type decursus: De...   \n",
       "9574  Samenvatting: \\nVerpleegkundige verslaglegging...   \n",
       "9575  Samenvatting: \\nMedisch Dossier\\r\\n[ Vk Sputov...   \n",
       "9576  Samenvatting: \\nVerpleegkundige verslaglegging...   \n",
       "\n",
       "     verslagen_report_start_date  \\\n",
       "0            2020-11-26 15:06:00   \n",
       "1            2020-11-26 09:53:00   \n",
       "2            2020-11-25 14:13:00   \n",
       "3            2020-11-25 13:48:00   \n",
       "4            2020-11-25 08:47:00   \n",
       "...                          ...   \n",
       "9572         2015-03-20 08:13:00   \n",
       "9573         2015-01-14 15:39:00   \n",
       "9574         2014-12-21 09:31:00   \n",
       "9575         2010-11-10 21:03:00   \n",
       "9576         2010-11-10 20:29:00   \n",
       "\n",
       "                       verslagen_report_content_cleaned  \\\n",
       "0     dhr aj dingemans huisarts streetname nr city d...   \n",
       "1     samenvatting rectaal bloedverlies obv divertik...   \n",
       "2     coloscopie betreft mw initials lastname adresg...   \n",
       "3     gastroscopie betreft mw initials lastname adre...   \n",
       "4     samenvatting rectaal bloedverlies eenmalig hd ...   \n",
       "...                                                 ...   \n",
       "9572  samenvatting e consult type e consult uitgebre...   \n",
       "9573  samenvatting decursus type decursus decursus s...   \n",
       "9574  samenvatting verpleegkundige verslaglegging ve...   \n",
       "9575  samenvatting medisch dossier vk sputovamo leef...   \n",
       "9576  samenvatting verpleegkundige verslaglegging ve...   \n",
       "\n",
       "                                          content_words  \\\n",
       "0     ['dhr', 'aj', 'dingemans', 'huisarts', 'street...   \n",
       "1     ['samenvatting', 'rectaal', 'bloedverlies', 'o...   \n",
       "2     ['coloscopie', 'betreft', 'mw', 'initials', 'l...   \n",
       "3     ['gastroscopie', 'betreft', 'mw', 'initials', ...   \n",
       "4     ['samenvatting', 'rectaal', 'bloedverlies', 'e...   \n",
       "...                                                 ...   \n",
       "9572  ['samenvatting', 'e', 'consult', 'type', 'e', ...   \n",
       "9573  ['samenvatting', 'decursus', 'type', 'decursus...   \n",
       "9574  ['samenvatting', 'verpleegkundige', 'verslagle...   \n",
       "9575  ['samenvatting', 'medisch', 'dossier', 'vk', '...   \n",
       "9576  ['samenvatting', 'verpleegkundige', 'verslagle...   \n",
       "\n",
       "                               content_words_lemmatized  \n",
       "0     ['dhr', 'aj', 'dingemans', 'huisarts', 'street...  \n",
       "1     ['samenvatting', 'rectaal', 'bloedverlie', 'ob...  \n",
       "2     ['coloscopie', 'betreffen', 'mw', 'initials', ...  \n",
       "3     ['gastroscopie', 'betreffen', 'mw', 'initials'...  \n",
       "4     ['samenvatting', 'rectaal', 'bloedverlie', 'ee...  \n",
       "...                                                 ...  \n",
       "9572  ['samenvatting', 'e', 'consult', 'type', 'e', ...  \n",
       "9573  ['samenvatting', 'decursus', 'type', 'decursus...  \n",
       "9574  ['samenvatting', 'verpleegkundig', 'verslagleg...  \n",
       "9575  ['samenvatting', 'Medisch', 'dossier', 'vk', '...  \n",
       "9576  ['samenvatting', 'verpleegkundig', 'verslagleg...  \n",
       "\n",
       "[9577 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_verslagen_clean = pd.read_csv('a:/df_verslagen_cleaned.csv')\n",
    "df_verslagen_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_id</th>\n",
       "      <th>activity</th>\n",
       "      <th>verslagen_report_content</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>verslagen_report_content_cleaned</th>\n",
       "      <th>content_words</th>\n",
       "      <th>content_words_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>046D1FFEBDD40E1665D0ABA6DD8FC9F8BC4351C6</td>\n",
       "      <td>Klinische Brief</td>\n",
       "      <td>Dhr. A.J. Dingemans, huisarts\\r\\n[STREETNAME] ...</td>\n",
       "      <td>2020-11-26 15:06:00</td>\n",
       "      <td>dhr aj dingemans huisarts streetname nr city d...</td>\n",
       "      <td>['dhr', 'aj', 'dingemans', 'huisarts', 'street...</td>\n",
       "      <td>['dhr', 'aj', 'dingemans', 'huisarts', 'street...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>046D1FFEBDD40E1665D0ABA6DD8FC9F8BC4351C6</td>\n",
       "      <td>Consult, Kliniek: vervolgconsult</td>\n",
       "      <td>Samenvatting: \\nRectaal bloedverlies obv diver...</td>\n",
       "      <td>2020-11-26 09:53:00</td>\n",
       "      <td>samenvatting rectaal bloedverlies obv divertik...</td>\n",
       "      <td>['samenvatting', 'rectaal', 'bloedverlies', 'o...</td>\n",
       "      <td>['samenvatting', 'rectaal', 'bloedverlie', 'ob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>046D1FFEBDD40E1665D0ABA6DD8FC9F8BC4351C6</td>\n",
       "      <td>Poliklinische Brief</td>\n",
       "      <td>COLOSCOPIE\\r\\n\\r\\nBetreft\\r\\nMw. [INITIALS] [L...</td>\n",
       "      <td>2020-11-25 14:13:00</td>\n",
       "      <td>coloscopie betreft mw initials lastname adresg...</td>\n",
       "      <td>['coloscopie', 'betreft', 'mw', 'initials', 'l...</td>\n",
       "      <td>['coloscopie', 'betreffen', 'mw', 'initials', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>046D1FFEBDD40E1665D0ABA6DD8FC9F8BC4351C6</td>\n",
       "      <td>Poliklinische Brief</td>\n",
       "      <td>GASTROSCOPIE\\r\\n\\r\\nBetreft\\r\\nMw. [INITIALS] ...</td>\n",
       "      <td>2020-11-25 13:48:00</td>\n",
       "      <td>gastroscopie betreft mw initials lastname adre...</td>\n",
       "      <td>['gastroscopie', 'betreft', 'mw', 'initials', ...</td>\n",
       "      <td>['gastroscopie', 'betreffen', 'mw', 'initials'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>046D1FFEBDD40E1665D0ABA6DD8FC9F8BC4351C6</td>\n",
       "      <td>Consult, Kliniek: vervolgconsult</td>\n",
       "      <td>Samenvatting: \\nRectaal bloedverlies ; eenmali...</td>\n",
       "      <td>2020-11-25 08:47:00</td>\n",
       "      <td>samenvatting rectaal bloedverlies eenmalig hd ...</td>\n",
       "      <td>['samenvatting', 'rectaal', 'bloedverlies', 'e...</td>\n",
       "      <td>['samenvatting', 'rectaal', 'bloedverlie', 'ee...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    case_id                          activity  \\\n",
       "0  046D1FFEBDD40E1665D0ABA6DD8FC9F8BC4351C6                   Klinische Brief   \n",
       "1  046D1FFEBDD40E1665D0ABA6DD8FC9F8BC4351C6  Consult, Kliniek: vervolgconsult   \n",
       "2  046D1FFEBDD40E1665D0ABA6DD8FC9F8BC4351C6               Poliklinische Brief   \n",
       "3  046D1FFEBDD40E1665D0ABA6DD8FC9F8BC4351C6               Poliklinische Brief   \n",
       "4  046D1FFEBDD40E1665D0ABA6DD8FC9F8BC4351C6  Consult, Kliniek: vervolgconsult   \n",
       "\n",
       "                            verslagen_report_content           timestamp  \\\n",
       "0  Dhr. A.J. Dingemans, huisarts\\r\\n[STREETNAME] ... 2020-11-26 15:06:00   \n",
       "1  Samenvatting: \\nRectaal bloedverlies obv diver... 2020-11-26 09:53:00   \n",
       "2  COLOSCOPIE\\r\\n\\r\\nBetreft\\r\\nMw. [INITIALS] [L... 2020-11-25 14:13:00   \n",
       "3  GASTROSCOPIE\\r\\n\\r\\nBetreft\\r\\nMw. [INITIALS] ... 2020-11-25 13:48:00   \n",
       "4  Samenvatting: \\nRectaal bloedverlies ; eenmali... 2020-11-25 08:47:00   \n",
       "\n",
       "                    verslagen_report_content_cleaned  \\\n",
       "0  dhr aj dingemans huisarts streetname nr city d...   \n",
       "1  samenvatting rectaal bloedverlies obv divertik...   \n",
       "2  coloscopie betreft mw initials lastname adresg...   \n",
       "3  gastroscopie betreft mw initials lastname adre...   \n",
       "4  samenvatting rectaal bloedverlies eenmalig hd ...   \n",
       "\n",
       "                                       content_words  \\\n",
       "0  ['dhr', 'aj', 'dingemans', 'huisarts', 'street...   \n",
       "1  ['samenvatting', 'rectaal', 'bloedverlies', 'o...   \n",
       "2  ['coloscopie', 'betreft', 'mw', 'initials', 'l...   \n",
       "3  ['gastroscopie', 'betreft', 'mw', 'initials', ...   \n",
       "4  ['samenvatting', 'rectaal', 'bloedverlies', 'e...   \n",
       "\n",
       "                            content_words_lemmatized  \n",
       "0  ['dhr', 'aj', 'dingemans', 'huisarts', 'street...  \n",
       "1  ['samenvatting', 'rectaal', 'bloedverlie', 'ob...  \n",
       "2  ['coloscopie', 'betreffen', 'mw', 'initials', ...  \n",
       "3  ['gastroscopie', 'betreffen', 'mw', 'initials'...  \n",
       "4  ['samenvatting', 'rectaal', 'bloedverlie', 'ee...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rename columns to match the event log\n",
    "df_verslagen_clean.rename(columns={'pseudo_id': 'case_id', 'verslagen_report_tags': 'activity', 'verslagen_report_start_date': 'timestamp'}, inplace=True)\n",
    "\n",
    "#make sure timestamp is in datetime format\n",
    "df_verslagen_clean['timestamp'] = pd.to_datetime(df_verslagen_clean['timestamp'])\n",
    "\n",
    "\n",
    "df_verslagen_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_verslagen_clean[['case_id', 'activity', 'timestamp']]  # Keep only the necessary columns\n",
    "df.to_csv('a:/df_verslagen_clean_event_log.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_verslagen_clean.to_csv('a:/df_verslagen_clean_event_log.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_id</th>\n",
       "      <th>activity</th>\n",
       "      <th>verslagen_report_content</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>046D1FFEBDD40E1665D0ABA6DD8FC9F8BC4351C6</td>\n",
       "      <td>Consult, Polikliniek: eerste consult</td>\n",
       "      <td>Reden van komst / Verwijzing: \\nReden verwijzi...</td>\n",
       "      <td>2022-02-01 08:33:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>046D1FFEBDD40E1665D0ABA6DD8FC9F8BC4351C6</td>\n",
       "      <td>Poliklinische Brief</td>\n",
       "      <td>Aan de weledelgeleerde vrouwe\\r\\ndrs. J.M.J. v...</td>\n",
       "      <td>2021-12-21 15:13:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>046D1FFEBDD40E1665D0ABA6DD8FC9F8BC4351C6</td>\n",
       "      <td>Consult, Polikliniek: vervolgconsult</td>\n",
       "      <td>Samenvatting: \\nVoorgeschiedenis\\ncholecystect...</td>\n",
       "      <td>2021-12-21 14:50:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>046D1FFEBDD40E1665D0ABA6DD8FC9F8BC4351C6</td>\n",
       "      <td>Radiologieverslag, ECG</td>\n",
       "      <td>Indicatie:\\nZie dossier\\n\\nSR; 67/MIN; LINKER ...</td>\n",
       "      <td>2021-12-16 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>046D1FFEBDD40E1665D0ABA6DD8FC9F8BC4351C6</td>\n",
       "      <td>Radiologieverslag, Thorax</td>\n",
       "      <td>Indicatie:\\nCRTH10X (CRTH10X): RÃ¶ntgen borstka...</td>\n",
       "      <td>2021-12-07 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    case_id  \\\n",
       "0  046D1FFEBDD40E1665D0ABA6DD8FC9F8BC4351C6   \n",
       "1  046D1FFEBDD40E1665D0ABA6DD8FC9F8BC4351C6   \n",
       "2  046D1FFEBDD40E1665D0ABA6DD8FC9F8BC4351C6   \n",
       "3  046D1FFEBDD40E1665D0ABA6DD8FC9F8BC4351C6   \n",
       "4  046D1FFEBDD40E1665D0ABA6DD8FC9F8BC4351C6   \n",
       "\n",
       "                               activity  \\\n",
       "0  Consult, Polikliniek: eerste consult   \n",
       "1                   Poliklinische Brief   \n",
       "2  Consult, Polikliniek: vervolgconsult   \n",
       "3                Radiologieverslag, ECG   \n",
       "4             Radiologieverslag, Thorax   \n",
       "\n",
       "                            verslagen_report_content           timestamp  \n",
       "0  Reden van komst / Verwijzing: \\nReden verwijzi... 2022-02-01 08:33:00  \n",
       "1  Aan de weledelgeleerde vrouwe\\r\\ndrs. J.M.J. v... 2021-12-21 15:13:00  \n",
       "2  Samenvatting: \\nVoorgeschiedenis\\ncholecystect... 2021-12-21 14:50:00  \n",
       "3  Indicatie:\\nZie dossier\\n\\nSR; 67/MIN; LINKER ... 2021-12-16 00:00:00  \n",
       "4  Indicatie:\\nCRTH10X (CRTH10X): RÃ¶ntgen borstka... 2021-12-07 00:00:00  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_alle_verslagen = pd.read_csv('a:/bloeding-met-patientenlijst-alle-soorten-verslagen/bloeding-met-patientenlijst-4-verslagen.csv')\n",
    "\n",
    "#rename columns to match the event log\n",
    "df_alle_verslagen.rename(columns={'pseudo_id': 'case_id', 'verslagen_report_tags': 'activity', 'verslagen_report_start_date': 'timestamp'}, inplace=True)\n",
    "\n",
    "#make sure timestamp is in datetime format\n",
    "df_alle_verslagen['timestamp'] = pd.to_datetime(df_alle_verslagen['timestamp'])\n",
    "\n",
    "\n",
    "df_alle_verslagen.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = df_alle_verslagen[['case_id', 'activity', 'timestamp']]  # Keep only the necessary columns\n",
    "df_2.to_csv('a:/df_alle_verslagen_event_log.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install spacy\n",
    "# !python -m spacy download nl_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Verpleegkundige', 'Dr.'}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"nl_core_news_sm\")\n",
    "\n",
    "text = \"\"\"\n",
    "Dr. Jan Jansen stelde de diagnose. Verpleegkundige Lisa de Vries assisteerde.\n",
    "Pieter de Boer, de chirurg, voerde de procedure uit.\n",
    "\"\"\"\n",
    "\n",
    "# Regex for names with \"Dr.\" or \"Verpleegkundige\"\n",
    "pattern = r\"(Dr\\.|Verpleegkundige)\\s+[A-Z][a-z]+\\s+(?:[a-z]+\\s+)?[A-Z][a-z]+\"\n",
    "regex_matches = re.findall(pattern, text)\n",
    "\n",
    "# Extract all names with spaCy\n",
    "doc = nlp(text)\n",
    "nlp_matches = [ent.text for ent in doc.ents if ent.label_ == \"PER\"]\n",
    "\n",
    "# Combine results\n",
    "all_names = set(regex_matches + nlp_matches)\n",
    "\n",
    "print(all_names)  # Output: {'Dr. Jan Jansen', 'Verpleegkundige Lisa de Vries', 'Pieter de Boer'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PatiÃ«nt werd gezien door Dr. Jan Jansen en verwezen naar Verpleegkundige Lisa de Vries.\n",
      "Dr. Pieter de Boer voerde de operatie uit.\n",
      "\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"nl_core_news_sm\")  # Load Dutch language model\n",
    "\n",
    "text = \"\"\"\n",
    "PatiÃ«nt werd gezien door Dr. Jan Jansen en verwezen naar Verpleegkundige Lisa de Vries.\n",
    "Dr. Pieter de Boer voerde de operatie uit.\n",
    "\"\"\"\n",
    "\n",
    "doc = nlp(text)\n",
    "print(doc)\n",
    "\n",
    "# Extract all named entities labeled as PERSON (Dutch: \"PER\")\n",
    "names = [ent.text for ent in doc.ents if ent.label_ == \"PER\"]\n",
    "\n",
    "print(names)  # Output: ['Jan Jansen', 'Lisa de Vries', 'Pieter de Boer']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Dr. Jan', 'Jan Jansen', 'Lisa de', 'de Vries', 'Dr. Pieter', 'Pieter de', 'de Boer']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "# Load Dutch language model\n",
    "nlp = spacy.load(\"nl_core_news_sm\")\n",
    "\n",
    "# Initialize pattern matcher\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# Define a pattern for detecting names (Proper nouns)\n",
    "pattern = [{\"POS\": \"PROPN\"}, {\"POS\": \"PROPN\"}]  # Matches two consecutive proper nouns\n",
    "\n",
    "matcher.add(\"PERSON_NAMES\", [pattern])\n",
    "\n",
    "text = \"\"\"\n",
    "PatiÃ«nt werd gezien door Dr. Jan Jansen en verwezen naar Verpleegkundige Lisa de Vries.\n",
    "Dr. Pieter de Boer voerde de operatie uit.\n",
    "\"\"\"\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "# Apply matcher to detect names\n",
    "matches = matcher(doc)\n",
    "names = [doc[start:end].text for match_id, start, end in matches]\n",
    "\n",
    "print(names)  # Output: ['Jan Jansen', 'Lisa de Vries', 'Pieter de Boer']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Verpleegkundige', 'de Vries', 'Lisa de', 'Dr. Jan', 'Jan Jansen', 'Pieter de', 'de Boer', 'Dr.'}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"nl_core_news_sm\")\n",
    "\n",
    "text = \"\"\"\n",
    "Dr. Jan Jansen stelde de diagnose. Verpleegkundige Lisa de Vries assisteerde.\n",
    "Pieter de Boer, de chirurg, voerde de procedure uit.\n",
    "\"\"\"\n",
    "\n",
    "# Regex pattern to catch \"Dr.\" or \"Verpleegkundige\"\n",
    "pattern = r\"(Dr\\.|Verpleegkundige)\\s+[A-Z][a-z]+\\s+(?:[a-z]+\\s+)?[A-Z][a-z]+\"\n",
    "regex_matches = re.findall(pattern, text)\n",
    "\n",
    "# Extract all names with spaCy's matcher\n",
    "doc = nlp(text)\n",
    "matcher = Matcher(nlp.vocab)\n",
    "matcher.add(\"PERSON_NAMES\", [[{\"POS\": \"PROPN\"}, {\"POS\": \"PROPN\"}]])\n",
    "matches = [doc[start:end].text for _, start, end in matcher(doc)]\n",
    "\n",
    "# Combine results\n",
    "all_names = set(regex_matches + matches)\n",
    "\n",
    "print(all_names)  # Output: {'Dr. Jan Jansen', 'Verpleegkundige Lisa de Vries', 'Pieter de Boer'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Dr.', 'Verpleegkundige', 'Dr.']\n",
      "['Dr. Jan', 'Dr. Jan Jansen', 'Jan Jansen', 'Lisa de', 'Lisa de Vries', 'de Vries', 'Pieter de', 'Pieter de Boer', 'de Boer', 'Dr. Marieke', 'Dr. Marieke van', 'Marieke van', 'Marieke van Dijk', 'van Dijk']\n",
      "{'Verpleegkundige', 'Marieke van', 'Dr. Marieke', 'de Vries', 'Lisa de', 'Dr. Jan Jansen', 'Dr. Marieke van', 'Dr. Jan', 'Lisa de Vries', 'Marieke van Dijk', 'van Dijk', 'Jan Jansen', 'Pieter de', 'de Boer', 'Pieter de Boer', 'Dr.'}\n",
      "{'Verpleegkundige', 'Dr. Marieke van', 'Dr. Jan Jansen', 'Marieke van Dijk', 'Lisa de Vries', 'Pieter de Boer'}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "nlp = spacy.load(\"nl_core_news_sm\")\n",
    "\n",
    "text = \"\"\"\n",
    "Dr. Jan Jansen stelde de diagnose. Verpleegkundige Lisa de Vries assisteerde.\n",
    "Pieter de Boer, de chirurg, voerde de procedure uit.\n",
    "Dr. Marieke van Dijk onderzocht de patiÃ«nt.\n",
    "\"\"\"\n",
    "\n",
    "# ðŸ”¹ Updated regex to capture full Dutch names with prefixes\n",
    "pattern = r\"(Dr\\.|Verpleegkundige)\\s+[A-Z][a-z]+(?:\\s+(?:van|de|der)\\s+[A-Z][a-z]+)?\"  \n",
    "\n",
    "regex_matches = re.findall(pattern, text)\n",
    "print(regex_matches)\n",
    "\n",
    "# Process text with spaCy\n",
    "doc = nlp(text)\n",
    "\n",
    "# ðŸ”¹ Matcher pattern for full Dutch names (supports prefixes)\n",
    "matcher = Matcher(nlp.vocab)\n",
    "pattern = [{\"POS\": \"PROPN\"}, {\"POS\": \"PROPN\"}, {\"POS\": \"PROPN\", \"OP\": \"?\"}]  # Captures 2- or 3-part names\n",
    "matcher.add(\"PERSON_NAMES\", [pattern])\n",
    "\n",
    "# Extract full names using spaCy\n",
    "matches = [doc[start:end].text for _, start, end in matcher(doc)]\n",
    "print(matches)\n",
    "\n",
    "# ðŸ”¹ Clean and filter duplicate/split names\n",
    "all_names = set(regex_matches + matches)\n",
    "print(all_names)\n",
    "# filtered_names = {name for name in all_names if len(name.split()) > 1}  # Remove single-word fragments\n",
    "# print(filtered_names)\n",
    "\n",
    "# Filter out partial duplicates, keeping the longest match\n",
    "final_names = set()\n",
    "for name in all_names:\n",
    "    if not any(name in other and name != other for other in all_names):\n",
    "        final_names.add(name)\n",
    "\n",
    "print(final_names)  # Output: {'Dr. Jan Jansen', 'Verpleegkundige Lisa de Vries', 'Pieter de Boer', 'Marieke van Dijk'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install clinlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Y.vanMegen\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\Y.vanMegen\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Y.vanMegen\\.cache\\huggingface\\hub\\models--UMCU--MedRoBERTa.nl_NegationDetection. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Y.vanMegen\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Y.vanMegen\\.cache\\huggingface\\hub\\models--UMCU--MedRoBERTa.nl_Experiencer. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import clinlp\n",
    "\n",
    "nlp = spacy.blank('clinlp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"De patient krijgt 2x daags 500 mg paracetamol.\"\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['De', 'patient', 'krijgt', '2', 'x', 'daags', '500', 'mg', 'paracetamol', '.']\n"
     ]
    }
   ],
   "source": [
    "print(list(token.text for token in doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<clinlp.sentencizer.Sentencizer at 0x11aa2bd6b10>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.add_pipe('clinlp_normalizer')\n",
    "nlp.add_pipe('clinlp_sentencizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['patient', 'krijgt', '2', 'x', 'daags', '500', 'mg', 'paracetamol', '.', 'de', 'patient', 'is', 'allergisch', 'voor', 'penicilline', '.']\n",
      "['PatiÃ«nt krijgt 2x daags 500 mg paracetamol.', 'De patiÃ«nt is allergisch voor penicilline.']\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\n",
    "    \"PatiÃ«nt krijgt 2x daags 500 mg \"\n",
    "    \"paracetamol. De patiÃ«nt is allergisch \"\n",
    "    \"voor penicilline.\"\n",
    ")\n",
    "\n",
    "\n",
    "print([token.norm_ for token in doc])\n",
    "# ['patient', 'krijgt', '2', 'x', 'daags', '500', 'mg', 'paracetamol', '.', 'de', 'patient', 'is', 'allergisch', 'voor', 'penicilline', '.']\n",
    "\n",
    "print([str(sent) for sent in doc.sents])\n",
    "# ['PatiÃ«nt krijgt 2x daags 500 mg paracetamol.', 'De patiÃ«nt is allergisch voor penicilline.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['clinlp_normalizer', 'clinlp_sentencizer']\n"
     ]
    }
   ],
   "source": [
    "print(nlp.pipe_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clinlp.ie import Term\n",
    "\n",
    "terms = {\n",
    "    \"prematuriteit\": [\n",
    "        \"preterm\", \"<p3\", \"prematuriteit\", \"partus praematurus\"\n",
    "    ],\n",
    "    \"hypotensie\": [\n",
    "        \"hypotensie\", Term(\"bd verlaagd\", proximity=1)\n",
    "    ],\n",
    "    \"veneus_infarct\": [\n",
    "        \"veneus infarct\", Term(\"VI\", attr=\"TEXT\")\n",
    "    ]\n",
    "}\n",
    "\n",
    "entity_matcher = nlp.add_pipe(\n",
    "    \"clinlp_rule_based_entity_matcher\", \n",
    "    config={\"attr\": \"NORM\", \"fuzzy\": 1}\n",
    ")\n",
    "\n",
    "entity_matcher.add_terms_from_dict(terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preterme prematuriteit\n",
      "<p3 prematuriteit\n",
      "bd enigszins verlaagd hypotensie\n",
      "hypotensie hypotensie\n",
      "veneus infarkt veneus_infarct\n",
      "partus prematurus prematuriteit\n",
      "VI veneus_infarct\n"
     ]
    }
   ],
   "source": [
    "text = (\n",
    "    \"Preterme neonaat (<p3) opgenomen, bd enigszins verlaagd, \"\n",
    "    \"familieanamnese vermeldt eveneens hypotensie bij moeder. \"\n",
    "    \"Thans geen aanwijzingen voor veneus infarkt wat ook geen \"\n",
    "    \"verklaring voor de partus prematurus is. Risico op VI \"\n",
    "    \"blijft aanwezig.\"\n",
    ")\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "for ent in doc.spans['ents']:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<clinlp.ie.qualifier.context_algorithm.ContextAlgorithm at 0x11abd3eeb10>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.add_pipe(\"clinlp_context_algorithm\", config={\"phrase_matcher_attr\": \"NORM\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preterme {Qualifier(name='Presence', value='Present', is_default=True, priority=0, prob=None), Qualifier(name='Temporality', value='Current', is_default=True, priority=0, prob=None), Qualifier(name='Experiencer', value='Patient', is_default=True, priority=0, prob=None)}\n",
      "<p3 {Qualifier(name='Presence', value='Present', is_default=True, priority=0, prob=None), Qualifier(name='Temporality', value='Current', is_default=True, priority=0, prob=None), Qualifier(name='Experiencer', value='Patient', is_default=True, priority=0, prob=None)}\n",
      "bd enigszins verlaagd {Qualifier(name='Presence', value='Present', is_default=True, priority=0, prob=None), Qualifier(name='Temporality', value='Current', is_default=True, priority=0, prob=None), Qualifier(name='Experiencer', value='Patient', is_default=True, priority=0, prob=None)}\n",
      "hypotensie {Qualifier(name='Presence', value='Present', is_default=True, priority=0, prob=None), Qualifier(name='Experiencer', value='Family', is_default=False, priority=2, prob=None), Qualifier(name='Temporality', value='Current', is_default=True, priority=0, prob=None)}\n",
      "veneus infarkt {Qualifier(name='Temporality', value='Current', is_default=True, priority=0, prob=None), Qualifier(name='Presence', value='Absent', is_default=False, priority=2, prob=None), Qualifier(name='Experiencer', value='Patient', is_default=True, priority=0, prob=None)}\n",
      "partus prematurus {Qualifier(name='Presence', value='Present', is_default=True, priority=0, prob=None), Qualifier(name='Temporality', value='Current', is_default=True, priority=0, prob=None), Qualifier(name='Experiencer', value='Patient', is_default=True, priority=0, prob=None)}\n",
      "VI {Qualifier(name='Presence', value='Present', is_default=True, priority=0, prob=None), Qualifier(name='Temporality', value='Future', is_default=False, priority=1, prob=None), Qualifier(name='Experiencer', value='Patient', is_default=True, priority=0, prob=None)}\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(text)\n",
    "\n",
    "for ent in doc.spans['ents']:\n",
    "    print(ent.text, ent._.qualifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from clinlp.data import InfoExtractionDataset\n",
    "\n",
    "# dataset = InfoExtractionDataset.from_json(\"data/mantra_gsc.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch transformers spacy\n",
    "# !python -m spacy download nl_core_news_lg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nl-core-news-lg==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/nl_core_news_lg-3.8.0/nl_core_news_lg-3.8.0-py3-none-any.whl (568.1 MB)\n",
      "     ---------------------------------------- 0.0/568.1 MB ? eta -:--:--\n",
      "     --------------------------------------- 2.4/568.1 MB 11.2 MB/s eta 0:00:51\n",
      "     --------------------------------------- 5.0/568.1 MB 11.6 MB/s eta 0:00:49\n",
      "      -------------------------------------- 7.3/568.1 MB 11.9 MB/s eta 0:00:48\n",
      "      ------------------------------------- 10.0/568.1 MB 11.7 MB/s eta 0:00:48\n",
      "      ------------------------------------- 10.7/568.1 MB 10.3 MB/s eta 0:00:54\n",
      "      -------------------------------------- 12.1/568.1 MB 9.7 MB/s eta 0:00:58\n",
      "     - ------------------------------------- 14.7/568.1 MB 9.9 MB/s eta 0:00:56\n",
      "     - ------------------------------------ 17.0/568.1 MB 10.2 MB/s eta 0:00:54\n",
      "     - ------------------------------------ 19.7/568.1 MB 10.4 MB/s eta 0:00:53\n",
      "     - ------------------------------------ 22.0/568.1 MB 10.5 MB/s eta 0:00:53\n",
      "     - ------------------------------------ 24.4/568.1 MB 10.6 MB/s eta 0:00:52\n",
      "     - ------------------------------------ 27.0/568.1 MB 10.7 MB/s eta 0:00:51\n",
      "     - ------------------------------------ 29.4/568.1 MB 10.8 MB/s eta 0:00:51\n",
      "     -- ----------------------------------- 32.0/568.1 MB 10.9 MB/s eta 0:00:50\n",
      "     -- ----------------------------------- 34.3/568.1 MB 10.9 MB/s eta 0:00:49\n",
      "     -- ----------------------------------- 36.7/568.1 MB 10.9 MB/s eta 0:00:49\n",
      "     -- ----------------------------------- 39.3/568.1 MB 11.1 MB/s eta 0:00:48\n",
      "     -- ----------------------------------- 41.7/568.1 MB 11.0 MB/s eta 0:00:48\n",
      "     -- ----------------------------------- 43.5/568.1 MB 11.0 MB/s eta 0:00:48\n",
      "     --- ---------------------------------- 46.1/568.1 MB 11.1 MB/s eta 0:00:48\n",
      "     --- ---------------------------------- 48.5/568.1 MB 11.1 MB/s eta 0:00:47\n",
      "     --- ---------------------------------- 50.9/568.1 MB 11.1 MB/s eta 0:00:47\n",
      "     --- ---------------------------------- 53.2/568.1 MB 11.1 MB/s eta 0:00:47\n",
      "     --- ---------------------------------- 55.8/568.1 MB 11.1 MB/s eta 0:00:46\n",
      "     --- ---------------------------------- 57.9/568.1 MB 11.1 MB/s eta 0:00:46\n",
      "     ---- --------------------------------- 60.3/568.1 MB 11.1 MB/s eta 0:00:46\n",
      "     ---- --------------------------------- 62.9/568.1 MB 11.2 MB/s eta 0:00:46\n",
      "     ---- --------------------------------- 65.3/568.1 MB 11.2 MB/s eta 0:00:45\n",
      "     ---- --------------------------------- 67.6/568.1 MB 11.2 MB/s eta 0:00:45\n",
      "     ---- --------------------------------- 70.3/568.1 MB 11.3 MB/s eta 0:00:45\n",
      "     ---- --------------------------------- 72.6/568.1 MB 11.3 MB/s eta 0:00:44\n",
      "     ----- -------------------------------- 75.2/568.1 MB 11.3 MB/s eta 0:00:44\n",
      "     ----- -------------------------------- 77.6/568.1 MB 11.3 MB/s eta 0:00:44\n",
      "     ----- -------------------------------- 80.0/568.1 MB 11.3 MB/s eta 0:00:44\n",
      "     ----- -------------------------------- 82.6/568.1 MB 11.3 MB/s eta 0:00:43\n",
      "     ----- -------------------------------- 84.9/568.1 MB 11.3 MB/s eta 0:00:43\n",
      "     ----- -------------------------------- 87.6/568.1 MB 11.4 MB/s eta 0:00:43\n",
      "     ------ ------------------------------- 90.2/568.1 MB 11.4 MB/s eta 0:00:43\n",
      "     ------ ------------------------------- 92.5/568.1 MB 11.4 MB/s eta 0:00:42\n",
      "     ------ ------------------------------- 95.2/568.1 MB 11.4 MB/s eta 0:00:42\n",
      "     ------ ------------------------------- 97.5/568.1 MB 11.4 MB/s eta 0:00:42\n",
      "     ------ ------------------------------- 99.9/568.1 MB 11.4 MB/s eta 0:00:41\n",
      "     ------ ------------------------------ 102.5/568.1 MB 11.4 MB/s eta 0:00:41\n",
      "     ------ ------------------------------ 104.9/568.1 MB 11.4 MB/s eta 0:00:41\n",
      "     ------- ----------------------------- 107.5/568.1 MB 11.4 MB/s eta 0:00:41\n",
      "     ------- ----------------------------- 109.8/568.1 MB 11.5 MB/s eta 0:00:40\n",
      "     ------- ----------------------------- 112.5/568.1 MB 11.5 MB/s eta 0:00:40\n",
      "     ------- ----------------------------- 115.1/568.1 MB 11.5 MB/s eta 0:00:40\n",
      "     ------- ----------------------------- 117.4/568.1 MB 11.5 MB/s eta 0:00:40\n",
      "     ------- ----------------------------- 119.8/568.1 MB 11.5 MB/s eta 0:00:40\n",
      "     ------- ----------------------------- 122.2/568.1 MB 11.5 MB/s eta 0:00:39\n",
      "     -------- ---------------------------- 124.3/568.1 MB 11.5 MB/s eta 0:00:39\n",
      "     -------- ---------------------------- 127.1/568.1 MB 11.5 MB/s eta 0:00:39\n",
      "     -------- ---------------------------- 129.8/568.1 MB 11.5 MB/s eta 0:00:39\n",
      "     -------- ---------------------------- 132.1/568.1 MB 11.5 MB/s eta 0:00:38\n",
      "     -------- ---------------------------- 134.7/568.1 MB 11.5 MB/s eta 0:00:38\n",
      "     -------- ---------------------------- 137.1/568.1 MB 11.5 MB/s eta 0:00:38\n",
      "     --------- --------------------------- 139.5/568.1 MB 11.5 MB/s eta 0:00:38\n",
      "     --------- --------------------------- 142.1/568.1 MB 11.5 MB/s eta 0:00:37\n",
      "     --------- --------------------------- 144.4/568.1 MB 11.5 MB/s eta 0:00:37\n",
      "     --------- --------------------------- 146.8/568.1 MB 11.5 MB/s eta 0:00:37\n",
      "     --------- --------------------------- 149.4/568.1 MB 11.6 MB/s eta 0:00:37\n",
      "     --------- --------------------------- 151.8/568.1 MB 11.6 MB/s eta 0:00:37\n",
      "     ---------- -------------------------- 154.1/568.1 MB 11.6 MB/s eta 0:00:36\n",
      "     ---------- -------------------------- 156.8/568.1 MB 11.6 MB/s eta 0:00:36\n",
      "     ---------- -------------------------- 159.4/568.1 MB 11.6 MB/s eta 0:00:36\n",
      "     ---------- -------------------------- 161.7/568.1 MB 11.6 MB/s eta 0:00:36\n",
      "     ---------- -------------------------- 164.1/568.1 MB 11.6 MB/s eta 0:00:35\n",
      "     ---------- -------------------------- 166.5/568.1 MB 11.6 MB/s eta 0:00:35\n",
      "     ----------- ------------------------- 169.1/568.1 MB 11.6 MB/s eta 0:00:35\n",
      "     ----------- ------------------------- 171.4/568.1 MB 11.6 MB/s eta 0:00:35\n",
      "     ----------- ------------------------- 174.1/568.1 MB 11.6 MB/s eta 0:00:35\n",
      "     ----------- ------------------------- 176.4/568.1 MB 11.6 MB/s eta 0:00:34\n",
      "     ----------- ------------------------- 178.8/568.1 MB 11.6 MB/s eta 0:00:34\n",
      "     ----------- ------------------------- 181.4/568.1 MB 11.6 MB/s eta 0:00:34\n",
      "     ----------- ------------------------- 183.8/568.1 MB 11.6 MB/s eta 0:00:34\n",
      "     ------------ ------------------------ 186.1/568.1 MB 11.6 MB/s eta 0:00:33\n",
      "     ------------ ------------------------ 188.7/568.1 MB 11.6 MB/s eta 0:00:33\n",
      "     ------------ ------------------------ 191.1/568.1 MB 11.6 MB/s eta 0:00:33\n",
      "     ------------ ------------------------ 193.5/568.1 MB 11.6 MB/s eta 0:00:33\n",
      "     ------------ ------------------------ 195.8/568.1 MB 11.6 MB/s eta 0:00:33\n",
      "     ------------ ------------------------ 198.4/568.1 MB 11.6 MB/s eta 0:00:32\n",
      "     ------------- ----------------------- 200.5/568.1 MB 11.6 MB/s eta 0:00:32\n",
      "     ------------- ----------------------- 202.9/568.1 MB 11.6 MB/s eta 0:00:32\n",
      "     ------------- ----------------------- 205.3/568.1 MB 11.6 MB/s eta 0:00:32\n",
      "     ------------- ----------------------- 207.9/568.1 MB 11.6 MB/s eta 0:00:32\n",
      "     ------------- ----------------------- 210.2/568.1 MB 11.6 MB/s eta 0:00:31\n",
      "     ------------- ----------------------- 212.9/568.1 MB 11.6 MB/s eta 0:00:31\n",
      "     -------------- ---------------------- 215.2/568.1 MB 11.6 MB/s eta 0:00:31\n",
      "     -------------- ---------------------- 217.8/568.1 MB 11.6 MB/s eta 0:00:31\n",
      "     -------------- ---------------------- 220.2/568.1 MB 11.6 MB/s eta 0:00:30\n",
      "     -------------- ---------------------- 222.8/568.1 MB 11.6 MB/s eta 0:00:30\n",
      "     -------------- ---------------------- 225.2/568.1 MB 11.6 MB/s eta 0:00:30\n",
      "     -------------- ---------------------- 227.8/568.1 MB 11.6 MB/s eta 0:00:30\n",
      "     -------------- ---------------------- 230.2/568.1 MB 11.6 MB/s eta 0:00:30\n",
      "     --------------- --------------------- 232.8/568.1 MB 11.6 MB/s eta 0:00:29\n",
      "     --------------- --------------------- 235.1/568.1 MB 11.6 MB/s eta 0:00:29\n",
      "     --------------- --------------------- 237.5/568.1 MB 11.6 MB/s eta 0:00:29\n",
      "     --------------- --------------------- 240.1/568.1 MB 11.6 MB/s eta 0:00:29\n",
      "     --------------- --------------------- 242.5/568.1 MB 11.6 MB/s eta 0:00:28\n",
      "     --------------- --------------------- 244.8/568.1 MB 11.6 MB/s eta 0:00:28\n",
      "     ---------------- -------------------- 247.5/568.1 MB 11.6 MB/s eta 0:00:28\n",
      "     ---------------- -------------------- 249.8/568.1 MB 11.6 MB/s eta 0:00:28\n",
      "     ---------------- -------------------- 252.2/568.1 MB 11.6 MB/s eta 0:00:28\n",
      "     ---------------- -------------------- 254.8/568.1 MB 11.6 MB/s eta 0:00:27\n",
      "     ---------------- -------------------- 257.2/568.1 MB 11.6 MB/s eta 0:00:27\n",
      "     ---------------- -------------------- 259.5/568.1 MB 11.6 MB/s eta 0:00:27\n",
      "     ----------------- ------------------- 262.1/568.1 MB 11.6 MB/s eta 0:00:27\n",
      "     ----------------- ------------------- 264.5/568.1 MB 11.6 MB/s eta 0:00:27\n",
      "     ----------------- ------------------- 267.1/568.1 MB 11.6 MB/s eta 0:00:26\n",
      "     ----------------- ------------------- 269.0/568.1 MB 11.6 MB/s eta 0:00:26\n",
      "     ----------------- ------------------- 271.6/568.1 MB 11.6 MB/s eta 0:00:26\n",
      "     ----------------- ------------------- 273.9/568.1 MB 11.7 MB/s eta 0:00:26\n",
      "     ----------------- ------------------- 276.3/568.1 MB 11.7 MB/s eta 0:00:25\n",
      "     ------------------ ------------------ 278.9/568.1 MB 11.7 MB/s eta 0:00:25\n",
      "     ------------------ ------------------ 281.5/568.1 MB 11.7 MB/s eta 0:00:25\n",
      "     ------------------ ------------------ 284.2/568.1 MB 11.7 MB/s eta 0:00:25\n",
      "     ------------------ ------------------ 286.5/568.1 MB 11.7 MB/s eta 0:00:24\n",
      "     ------------------ ------------------ 289.1/568.1 MB 11.7 MB/s eta 0:00:24\n",
      "     ------------------ ------------------ 291.5/568.1 MB 11.7 MB/s eta 0:00:24\n",
      "     ------------------- ----------------- 294.1/568.1 MB 11.7 MB/s eta 0:00:24\n",
      "     ------------------- ----------------- 296.5/568.1 MB 11.7 MB/s eta 0:00:24\n",
      "     ------------------- ----------------- 298.8/568.1 MB 11.7 MB/s eta 0:00:23\n",
      "     ------------------- ----------------- 300.9/568.1 MB 11.7 MB/s eta 0:00:23\n",
      "     ------------------- ----------------- 303.6/568.1 MB 11.7 MB/s eta 0:00:23\n",
      "     ------------------- ----------------- 306.2/568.1 MB 11.8 MB/s eta 0:00:23\n",
      "     -------------------- ---------------- 308.8/568.1 MB 11.8 MB/s eta 0:00:23\n",
      "     -------------------- ---------------- 311.2/568.1 MB 11.8 MB/s eta 0:00:22\n",
      "     -------------------- ---------------- 313.8/568.1 MB 11.8 MB/s eta 0:00:22\n",
      "     -------------------- ---------------- 316.1/568.1 MB 11.8 MB/s eta 0:00:22\n",
      "     -------------------- ---------------- 318.8/568.1 MB 11.8 MB/s eta 0:00:22\n",
      "     -------------------- ---------------- 321.4/568.1 MB 11.8 MB/s eta 0:00:21\n",
      "     --------------------- --------------- 324.0/568.1 MB 11.8 MB/s eta 0:00:21\n",
      "     --------------------- --------------- 326.6/568.1 MB 11.8 MB/s eta 0:00:21\n",
      "     --------------------- --------------- 329.0/568.1 MB 11.8 MB/s eta 0:00:21\n",
      "     --------------------- --------------- 331.4/568.1 MB 11.8 MB/s eta 0:00:21\n",
      "     --------------------- --------------- 334.0/568.1 MB 11.8 MB/s eta 0:00:20\n",
      "     --------------------- --------------- 336.3/568.1 MB 11.8 MB/s eta 0:00:20\n",
      "     ---------------------- -------------- 339.0/568.1 MB 11.8 MB/s eta 0:00:20\n",
      "     ---------------------- -------------- 341.3/568.1 MB 11.8 MB/s eta 0:00:20\n",
      "     ---------------------- -------------- 343.7/568.1 MB 11.8 MB/s eta 0:00:20\n",
      "     ---------------------- -------------- 346.3/568.1 MB 11.8 MB/s eta 0:00:19\n",
      "     ---------------------- -------------- 348.9/568.1 MB 11.8 MB/s eta 0:00:19\n",
      "     ---------------------- -------------- 351.3/568.1 MB 11.8 MB/s eta 0:00:19\n",
      "     ----------------------- ------------- 353.9/568.1 MB 11.8 MB/s eta 0:00:19\n",
      "     ----------------------- ------------- 356.3/568.1 MB 11.8 MB/s eta 0:00:18\n",
      "     ----------------------- ------------- 358.6/568.1 MB 11.8 MB/s eta 0:00:18\n",
      "     ----------------------- ------------- 361.2/568.1 MB 11.8 MB/s eta 0:00:18\n",
      "     ----------------------- ------------- 363.9/568.1 MB 11.8 MB/s eta 0:00:18\n",
      "     ----------------------- ------------- 366.2/568.1 MB 11.8 MB/s eta 0:00:18\n",
      "     ------------------------ ------------ 368.8/568.1 MB 11.8 MB/s eta 0:00:17\n",
      "     ------------------------ ------------ 371.2/568.1 MB 11.8 MB/s eta 0:00:17\n",
      "     ------------------------ ------------ 373.8/568.1 MB 11.8 MB/s eta 0:00:17\n",
      "     ------------------------ ------------ 376.2/568.1 MB 11.8 MB/s eta 0:00:17\n",
      "     ------------------------ ------------ 378.5/568.1 MB 11.8 MB/s eta 0:00:17\n",
      "     ------------------------ ------------ 381.2/568.1 MB 11.8 MB/s eta 0:00:16\n",
      "     ------------------------ ------------ 383.5/568.1 MB 11.8 MB/s eta 0:00:16\n",
      "     ------------------------- ----------- 386.1/568.1 MB 11.8 MB/s eta 0:00:16\n",
      "     ------------------------- ----------- 388.5/568.1 MB 11.8 MB/s eta 0:00:16\n",
      "     ------------------------- ----------- 390.9/568.1 MB 11.8 MB/s eta 0:00:16\n",
      "     ------------------------- ----------- 393.2/568.1 MB 11.8 MB/s eta 0:00:15\n",
      "     ------------------------- ----------- 395.8/568.1 MB 11.8 MB/s eta 0:00:15\n",
      "     ------------------------- ----------- 398.2/568.1 MB 11.8 MB/s eta 0:00:15\n",
      "     -------------------------- ---------- 400.8/568.1 MB 11.8 MB/s eta 0:00:15\n",
      "     -------------------------- ---------- 403.2/568.1 MB 11.8 MB/s eta 0:00:15\n",
      "     -------------------------- ---------- 405.5/568.1 MB 11.8 MB/s eta 0:00:14\n",
      "     -------------------------- ---------- 408.2/568.1 MB 11.8 MB/s eta 0:00:14\n",
      "     -------------------------- ---------- 410.5/568.1 MB 11.8 MB/s eta 0:00:14\n",
      "     -------------------------- ---------- 413.1/568.1 MB 11.8 MB/s eta 0:00:14\n",
      "     --------------------------- --------- 415.5/568.1 MB 11.8 MB/s eta 0:00:13\n",
      "     --------------------------- --------- 418.1/568.1 MB 11.8 MB/s eta 0:00:13\n",
      "     --------------------------- --------- 420.5/568.1 MB 11.8 MB/s eta 0:00:13\n",
      "     --------------------------- --------- 423.1/568.1 MB 11.8 MB/s eta 0:00:13\n",
      "     --------------------------- --------- 425.5/568.1 MB 11.8 MB/s eta 0:00:13\n",
      "     --------------------------- --------- 428.1/568.1 MB 11.8 MB/s eta 0:00:12\n",
      "     ---------------------------- -------- 430.4/568.1 MB 11.8 MB/s eta 0:00:12\n",
      "     ---------------------------- -------- 433.1/568.1 MB 11.8 MB/s eta 0:00:12\n",
      "     ---------------------------- -------- 435.4/568.1 MB 11.8 MB/s eta 0:00:12\n",
      "     ---------------------------- -------- 438.0/568.1 MB 11.8 MB/s eta 0:00:12\n",
      "     ---------------------------- -------- 440.7/568.1 MB 11.8 MB/s eta 0:00:11\n",
      "     ---------------------------- -------- 443.0/568.1 MB 11.8 MB/s eta 0:00:11\n",
      "     ----------------------------- ------- 445.4/568.1 MB 11.8 MB/s eta 0:00:11\n",
      "     ----------------------------- ------- 448.0/568.1 MB 11.8 MB/s eta 0:00:11\n",
      "     ----------------------------- ------- 450.1/568.1 MB 11.8 MB/s eta 0:00:11\n",
      "     ----------------------------- ------- 452.7/568.1 MB 11.8 MB/s eta 0:00:10\n",
      "     ----------------------------- ------- 455.1/568.1 MB 11.8 MB/s eta 0:00:10\n",
      "     ----------------------------- ------- 457.4/568.1 MB 11.8 MB/s eta 0:00:10\n",
      "     ----------------------------- ------- 460.1/568.1 MB 11.8 MB/s eta 0:00:10\n",
      "     ------------------------------ ------ 462.7/568.1 MB 11.8 MB/s eta 0:00:09\n",
      "     ------------------------------ ------ 465.0/568.1 MB 11.8 MB/s eta 0:00:09\n",
      "     ------------------------------ ------ 467.4/568.1 MB 11.8 MB/s eta 0:00:09\n",
      "     ------------------------------ ------ 470.0/568.1 MB 11.8 MB/s eta 0:00:09\n",
      "     ------------------------------ ------ 472.6/568.1 MB 11.8 MB/s eta 0:00:09\n",
      "     ------------------------------ ------ 475.3/568.1 MB 11.8 MB/s eta 0:00:08\n",
      "     ------------------------------- ----- 477.6/568.1 MB 11.8 MB/s eta 0:00:08\n",
      "     ------------------------------- ----- 480.0/568.1 MB 11.8 MB/s eta 0:00:08\n",
      "     ------------------------------- ----- 482.6/568.1 MB 11.8 MB/s eta 0:00:08\n",
      "     ------------------------------- ----- 485.0/568.1 MB 11.8 MB/s eta 0:00:08\n",
      "     ------------------------------- ----- 487.6/568.1 MB 11.8 MB/s eta 0:00:07\n",
      "     ------------------------------- ----- 490.2/568.1 MB 11.8 MB/s eta 0:00:07\n",
      "     -------------------------------- ---- 492.3/568.1 MB 11.8 MB/s eta 0:00:07\n",
      "     -------------------------------- ---- 495.2/568.1 MB 11.8 MB/s eta 0:00:07\n",
      "     -------------------------------- ---- 497.8/568.1 MB 11.8 MB/s eta 0:00:06\n",
      "     -------------------------------- ---- 500.4/568.1 MB 11.8 MB/s eta 0:00:06\n",
      "     -------------------------------- ---- 502.8/568.1 MB 11.8 MB/s eta 0:00:06\n",
      "     -------------------------------- ---- 505.4/568.1 MB 11.8 MB/s eta 0:00:06\n",
      "     --------------------------------- --- 508.0/568.1 MB 11.8 MB/s eta 0:00:06\n",
      "     --------------------------------- --- 510.4/568.1 MB 11.8 MB/s eta 0:00:05\n",
      "     --------------------------------- --- 513.0/568.1 MB 11.8 MB/s eta 0:00:05\n",
      "     --------------------------------- --- 515.4/568.1 MB 11.8 MB/s eta 0:00:05\n",
      "     --------------------------------- --- 518.0/568.1 MB 11.8 MB/s eta 0:00:05\n",
      "     --------------------------------- --- 520.4/568.1 MB 11.8 MB/s eta 0:00:05\n",
      "     ---------------------------------- -- 523.0/568.1 MB 11.8 MB/s eta 0:00:04\n",
      "     ---------------------------------- -- 525.3/568.1 MB 11.8 MB/s eta 0:00:04\n",
      "     ---------------------------------- -- 528.0/568.1 MB 11.8 MB/s eta 0:00:04\n",
      "     ---------------------------------- -- 530.3/568.1 MB 11.8 MB/s eta 0:00:04\n",
      "     ---------------------------------- -- 532.9/568.1 MB 11.8 MB/s eta 0:00:03\n",
      "     ---------------------------------- -- 535.3/568.1 MB 11.8 MB/s eta 0:00:03\n",
      "     ----------------------------------- - 537.7/568.1 MB 11.8 MB/s eta 0:00:03\n",
      "     ----------------------------------- - 540.0/568.1 MB 11.8 MB/s eta 0:00:03\n",
      "     ----------------------------------- - 542.6/568.1 MB 11.8 MB/s eta 0:00:03\n",
      "     ----------------------------------- - 545.0/568.1 MB 11.8 MB/s eta 0:00:02\n",
      "     ----------------------------------- - 547.4/568.1 MB 11.8 MB/s eta 0:00:02\n",
      "     ----------------------------------- - 549.7/568.1 MB 11.8 MB/s eta 0:00:02\n",
      "     ----------------------------------- - 552.3/568.1 MB 11.8 MB/s eta 0:00:02\n",
      "     ------------------------------------  555.0/568.1 MB 11.8 MB/s eta 0:00:02\n",
      "     ------------------------------------  557.3/568.1 MB 11.8 MB/s eta 0:00:01\n",
      "     ------------------------------------  559.9/568.1 MB 11.8 MB/s eta 0:00:01\n",
      "     ------------------------------------  562.3/568.1 MB 11.8 MB/s eta 0:00:01\n",
      "     ------------------------------------  564.9/568.1 MB 11.8 MB/s eta 0:00:01\n",
      "     ------------------------------------  567.3/568.1 MB 11.8 MB/s eta 0:00:01\n",
      "     ------------------------------------  567.8/568.1 MB 11.8 MB/s eta 0:00:01\n",
      "     ------------------------------------  567.8/568.1 MB 11.8 MB/s eta 0:00:01\n",
      "     ------------------------------------  567.8/568.1 MB 11.8 MB/s eta 0:00:01\n",
      "     ------------------------------------  567.8/568.1 MB 11.8 MB/s eta 0:00:01\n",
      "     ------------------------------------  567.8/568.1 MB 11.8 MB/s eta 0:00:01\n",
      "     ------------------------------------  567.8/568.1 MB 11.8 MB/s eta 0:00:01\n",
      "     ------------------------------------- 568.1/568.1 MB 11.2 MB/s eta 0:00:00\n",
      "Installing collected packages: nl-core-news-lg\n",
      "Successfully installed nl-core-news-lg-3.8.0\n",
      "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('nl_core_news_lg')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Y.vanMegen\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Y.vanMegen\\.cache\\huggingface\\hub\\models--CLTL--MedRoBERTa.nl. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at CLTL/MedRoBERTa.nl and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Device set to use cpu\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nlp_roberta: <transformers.pipelines.token_classification.TokenClassificationPipeline object at 0x0000011ABE924E10>\n",
      "doc: \n",
      "Dr. Jan de Vries is een cardioloog in het Erasmus MC. Verpleegkundige Sarah Jansen werkt op de IC-afdeling.\n",
      "Dr. Kees van Dijk is neurochirurg.\n",
      "\n",
      "ent: Jan de Vries\n",
      "ent: Erasmus MC\n",
      "ent: Sarah Jansen\n",
      "ent: Kees van Dijk\n",
      "word: ÄŠ\n",
      "word: Dr\n",
      "word: .\n",
      "word: Ä Jan\n",
      "word: Ä de\n",
      "word: Ä Vries\n",
      "word: Ä is\n",
      "word: Ä een\n",
      "word: Ä cardioloog\n",
      "word: Ä in\n",
      "word: Ä het\n",
      "word: Ä Erasmus\n",
      "word: Ä MC\n",
      "word: .\n",
      "word: Ä Verpleegkundige\n",
      "word: Ä Sara\n",
      "word: h\n",
      "word: Ä Jan\n",
      "word: sen\n",
      "word: Ä werkt\n",
      "word: Ä op\n",
      "word: Ä de\n",
      "word: Ä IC\n",
      "word: -\n",
      "word: afdeling\n",
      "word: .\n",
      "word: ÄŠ\n",
      "word: Dr\n",
      "word: .\n",
      "word: Ä K\n",
      "word: ees\n",
      "word: Ä van\n",
      "word: Ä Dijk\n",
      "word: Ä is\n",
      "word: Ä neurochirurg\n",
      "word: .\n",
      "word: ÄŠ\n",
      "r: {'naam': 'Jan de Vries', 'functie': 'Ä Verpleegkundige'}\n",
      "Naam: Jan de Vries, Functie: Ä Verpleegkundige\n",
      "r: {'naam': 'Sarah Jansen', 'functie': 'Ä Verpleegkundige'}\n",
      "Naam: Sarah Jansen, Functie: Ä Verpleegkundige\n",
      "r: {'naam': 'Kees van Dijk', 'functie': 'Ä Verpleegkundige'}\n",
      "Naam: Kees van Dijk, Functie: Ä Verpleegkundige\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from transformers import AutoModelForTokenClassification, AutoTokenizer, pipeline\n",
    "\n",
    "# Ensure the Dutch language model is installed\n",
    "# !python -m spacy download nl_core_news_lg\n",
    "\n",
    "# Laad het Nederlandse spaCy-model voor NER\n",
    "nlp = spacy.load(\"nl_core_news_lg\")\n",
    "\n",
    "# Laad MedRoBERTa.nl model en tokenizer\n",
    "# model_name = \"GroNLP/medroberta-base\"\n",
    "model_name = \"CLTL/MedRoBERTa.nl\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
    "\n",
    "# Gebruik Hugging Face pipeline voor tokenclassificatie\n",
    "nlp_roberta = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
    "print('nlp_roberta:', nlp_roberta)\n",
    "\n",
    "def extract_medical_entities(text):\n",
    "    doc = nlp(text)\n",
    "    print('doc:', doc)\n",
    "    \n",
    "    professionals = []\n",
    "    \n",
    "    # Zoek naar persoonsnamen en functies met spaCy\n",
    "    for ent in doc.ents:\n",
    "        print('ent:', ent)\n",
    "        if ent.label_ in [\"PERSON\"]:  # Herkent namen\n",
    "            professionals.append({\"naam\": ent.text, \"functie\": None})\n",
    "\n",
    "    # Zoek naar medische functies met MedRoBERTa.nl\n",
    "    roberta_results = nlp_roberta(text)\n",
    "    for result in roberta_results:\n",
    "        # print('result:', result)\n",
    "        word = result['word']\n",
    "        print('word:', word)\n",
    "        label = result['entity']  # De entiteit die MedRoBERTa herkent\n",
    "        # print('label:', label)\n",
    "        \n",
    "        if \"arts\" in word.lower() or \"verpleegkundige\" in word.lower():\n",
    "            for person in professionals:\n",
    "                if person[\"functie\"] is None:\n",
    "                    person[\"functie\"] = word\n",
    "\n",
    "    return professionals\n",
    "\n",
    "# ðŸ” **Test met voorbeeldtekst**\n",
    "tekst = \"\"\"\n",
    "Dr. Jan de Vries is een cardioloog in het Erasmus MC. Verpleegkundige Sarah Jansen werkt op de IC-afdeling.\n",
    "Dr. Kees van Dijk is neurochirurg.\n",
    "\"\"\"\n",
    "\n",
    "resultaten = extract_medical_entities(tekst)\n",
    "for r in resultaten:\n",
    "    print('r:', r)\n",
    "    print(f\"Naam: {r['naam']}, Functie: {r['functie']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at CLTL/MedRoBERTa.nl and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PatiÃƒÂ«nt', 'Ä krijgt', 'Ä 2', 'x', 'Ä daags', 'Ä 500', 'Ä mg', 'Ä paracetamol', '.', 'Ä De', 'Ä patiÃƒÂ«nt', 'Ä is', 'Ä allergisch', 'Ä voor', 'Ä penicilline', '.']\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"CLTL/MedRoBERTa.nl\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"CLTL/MedRoBERTa.nl\")\n",
    "\n",
    "# Tokenize the input text\n",
    "input_text = \"PatiÃ«nt krijgt 2x daags 500 mg paracetamol. De patiÃ«nt is allergisch voor penicilline.\"\n",
    "tokens = tokenizer.tokenize(input_text)\n",
    "\n",
    "# Normalize the tokens\n",
    "# normalized_tokens = [token.replace(\"Ä \", \"\") for token in tokens]\n",
    "\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vandaag vooral bezig geweest met de process mining en kijken wat er nu gebeurd. Er zitten best wat verschillen tussen beide datasets, maar ik denk dat de kleinere dataset over het algemeen goed genoeg is. bij de uitgebreide krijg je heel veel radiologieverslagen en die zijn denk ik niet zo relevant voor GIB. Cardiologie heb ik nog niet specifiek naar gekeken, maar kan wel een interessant iets zijn. \n",
    "\n",
    "Voor morgen wil ik verder met kijken of ik namen uit de tekst kan halen en hun functie. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
